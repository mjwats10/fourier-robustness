{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTPKb6-JkQ81","executionInfo":{"status":"ok","timestamp":1664479612544,"user_tz":420,"elapsed":14622,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"d60667b0-d2e0-448d-af8d-77109c616475"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11085,"status":"ok","timestamp":1664479623626,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"},"user_tz":420},"id":"wDjjZFaGNZXV","outputId":"9117dcd1-57d2-4ee2-97a7-f7d0e62b466c"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.12.1+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyefd\n","  Downloading pyefd-1.6.0-py2.py3-none-any.whl (7.7 kB)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyefd) (1.21.6)\n","Installing collected packages: pyefd\n","Successfully installed pyefd-1.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cairocffi\n","  Downloading cairocffi-1.4.0.tar.gz (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 3.6 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n","Building wheels for collected packages: cairocffi\n","  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cairocffi: filename=cairocffi-1.4.0-py3-none-any.whl size=88775 sha256=0664989eca961d8c996bb928f257570418851306c53d28f30ab7f8cc804210a0\n","  Stored in directory: /root/.cache/pip/wheels/7a/2b/da/aec872f95d2c24105496ef149a9a576f52daf686f8f2127541\n","Successfully built cairocffi\n","Installing collected packages: cairocffi\n","Successfully installed cairocffi-1.4.0\n"]}],"source":["import os\n","import torch\n","print(torch.__version__)\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms as T\n","import random\n","import cv2\n","import numpy as np\n","!pip install pyefd\n","import pyefd\n","from google.colab.patches import cv2_imshow\n","!pip install cairocffi\n","import cairocffi as cairo\n","import struct\n","from struct import unpack"]},{"cell_type":"markdown","metadata":{"id":"ZSpVSjCyUPb6"},"source":["Section 1: Fourier Descriptors through linear classifier"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"q9cgJ84nZ1qR","executionInfo":{"status":"ok","timestamp":1664479623626,"user_tz":420,"elapsed":3,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}}},"outputs":[],"source":["# Env vars\n","torch.use_deterministic_algorithms(False)\n","\n","# Const vars\n","LOAD_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25-2 MLP vector single-wide.pt'\n","RAND_SEED = 0\n","DEVICE = \"cuda\"\n","\n","IMG_SIDE = 256\n","NUM_CLASSES = 25\n","EPOCHS = 10\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 512\n","LOSS_FN = nn.CrossEntropyLoss()\n","FOURIER_ORDER = 10"]},{"cell_type":"code","source":["def get_step(deltaX, deltaY):\n","  angle = np.arctan2(deltaY, deltaX)\n","  pi_over_8 = np.pi / 8\n","  if -pi_over_8 <= angle < pi_over_8:\n","    return (1, 0)\n","  elif pi_over_8 <= angle < 3 * pi_over_8:\n","    return (1, 1)\n","  elif 3 * pi_over_8 <= angle < 5 * pi_over_8:\n","    return (0, 1)\n","  elif 5 * pi_over_8 <= angle < 7 * pi_over_8:\n","    return (-1, 1)\n","  elif angle >= 7 * pi_over_8 or angle < -7 * pi_over_8:\n","    return (-1, 0)\n","  elif -7 * pi_over_8 <= angle < -5 * pi_over_8:\n","    return (-1, -1)\n","  elif -5 * pi_over_8 <= angle < -3 * pi_over_8:\n","    return (0, -1)\n","  else:\n","    return (1, -1)\n","\n","def complete_contour(vector_img):\n","  complete_contour = []\n","  partial_contour = [point for stroke in vector_img for point in zip(*stroke)]\n","  if len(partial_contour) > 0:\n","    partial_contour.append(partial_contour[0])\n","    for i in range(len(partial_contour) - 1):\n","      x0, y0 = partial_contour[i]\n","      x1, y1 = partial_contour[i+1]\n","      if (x0, y0) == (x1, y1):\n","        continue\n","      complete_contour.append([x0, y0])\n","      deltaX = x1 - x0\n","      deltaY = y1 - y0\n","      while(max(abs(deltaX), abs(deltaY)) > 1):\n","        x_offset, y_offset = get_step(deltaX, deltaY)\n","        x0 += x_offset\n","        y0 += y_offset\n","        complete_contour.append([x0, y0])\n","        deltaX = x1 - x0\n","        deltaY = y1 - y0\n","  return np.asarray(complete_contour)\n","\n","means = np.asarray([[1.00000000e+00,  1.70292625e-19,  1.37157261e-19, -2.97352773e-02],\n"," [ 3.93857845e-02,  1.14573042e-02,  1.11273905e-02, -1.27501456e-02],\n"," [ 1.26057258e-02,  1.27047894e-02,  2.20446418e-03, -5.17296120e-03],\n"," [ 4.60867346e-03,  2.54431263e-04, -2.24875991e-03, -2.43568670e-03],\n"," [-1.29011658e-03,  7.29537187e-04,  3.29306713e-04, -6.94848183e-05],\n"," [-2.20461684e-03, -4.26032423e-04,  3.70747798e-04,  6.67042619e-04],\n"," [ 1.06105248e-03,  5.59965312e-04, -2.48033261e-05, -3.27838867e-04],\n"," [ 6.92991267e-04,  7.77918380e-05,  1.26802111e-04, -4.82832044e-04],\n"," [ 2.05231401e-04, -1.29655496e-04, -1.44908870e-04, -2.86502180e-04],\n"," [-1.48524853e-04, -2.01465364e-04,  2.28534063e-04,  3.38029409e-04]])\n","\n","stdevs = np.asarray([[1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 3.94827207e-01],\n"," [6.15715499e-01, 6.31045641e-01, 5.56262445e-01, 5.77054655e-01],\n"," [4.44723755e-01, 4.34617210e-01, 4.14754373e-01, 4.09847350e-01],\n"," [3.13965726e-01, 3.06039399e-01, 2.93664393e-01, 2.88944168e-01],\n"," [2.20598291e-01, 2.20428499e-01, 2.08627310e-01, 2.08939754e-01],\n"," [1.67779200e-01, 1.70621159e-01, 1.61133731e-01, 1.60840793e-01],\n"," [1.35504574e-01, 1.33753600e-01, 1.28539543e-01, 1.29087092e-01],\n"," [1.08136940e-01, 1.08601151e-01, 1.04438585e-01, 1.03887367e-01],\n"," [9.21341521e-02, 9.22050837e-02, 8.90123677e-02, 8.74814102e-02],\n"," [7.74686779e-02, 7.69117614e-02, 7.27067303e-02, 7.27266299e-02]])\n"," \n","# transform functions - take sketch image, return torch tensor of descriptors\n","def fourier_transform(vector_img, is_test):\n","  contour = complete_contour(vector_img)\n","\n","  if is_test: \n","    angle = random.random() * 60 - 30\n","    deltaX = random.randint(-3, 3)\n","    deltaY = random.randint(-3, 3)\n","\n","    # linear algebra to apply randomly generated transformations to the digit contour\n","    theta = np.radians(angle)\n","    sin, cos = np.sin(theta), np.cos(theta)\n","    rotation = np.array(((cos, -sin), (sin, cos)))\n","    translation = np.array((deltaX, deltaY))\n","    contour = np.transpose(np.dot(rotation, np.transpose(contour))) + translation\n","  \n","  coeffs = pyefd.elliptic_fourier_descriptors(contour, order=FOURIER_ORDER, normalize=True)\n","  coeffs = (coeffs - means) / stdevs\n","  return torch.from_numpy(coeffs.flatten()).float()\n","\n","# helper method to find class based on imgset index\n","def find_class(idx, num_list):\n","  class_id = 0\n","  sum = num_list[class_id]\n","  while idx >= sum:\n","    class_id += 1\n","    sum += num_list[class_id]\n","  return class_id\n","\n","# deterministic worker re-seeding\n","def seed_worker(worker_id):\n","  worker_seed = torch.initial_seed() % 2**32\n","  np.random.seed(worker_seed)\n","  random.seed(worker_seed)\n","\n","# custom dataset for quickdraw\n","class QuickdrawDataset(Dataset):\n","  def __init__(self, imgs, nums, is_test):\n","    self.imgs = imgs\n","    self.nums = nums\n","    self.len = sum(nums)\n","    self.is_test = is_test\n","\n","  def __len__(self):\n","    return self.len\n","\n","  def __getitem__(self, idx):\n","    img = self.imgs[idx]\n","    x = fourier_transform(img, self.is_test)\n","    y = find_class(idx, self.nums)\n","    return x, y\n","\n","\n","class MLP(torch.nn.Module):\n","  def __init__(self):\n","    super(MLP, self).__init__()\n","    self.fc1 = nn.Linear(FOURIER_ORDER * 4, 1024)\n","    self.fc2 = nn.Linear(1024, 1024)\n","    self.fc3 = nn.Linear(1024, 1024)\n","    self.head = nn.Linear(1024, NUM_CLASSES)\n","    self.relu = nn.ReLU()\n","\n","\n","  def forward(self, x):\n","    x = self.fc1(x)\n","    x = self.relu(x)\n","    x = self.fc2(x)\n","    x = self.relu(x)\n","    x = self.fc3(x)\n","    x = self.relu(x)\n","    return self.head(x)\n","\n","\n","def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train() # put the model in train mode\n","    total_loss = 0\n","    total_correct = 0\n","    # for each batch in the training set compute loss and update model parameters\n","    for batch, (x, y) in enumerate(dataloader):\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      # Compute prediction and loss\n","      out = model(x)\n","      loss = loss_fn(out, y)\n","\n","      # Backpropagation to update model parameters\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # print current training metrics for user\n","      y, out, loss = y.to(\"cpu\"), out.to(\"cpu\"), loss.to(\"cpu\")\n","      loss_val = loss.item()\n","      if batch % 20 == 0:\n","          current = (batch + 1) * BATCH_SIZE\n","          print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","      pred = out.argmax(dim=1, keepdim=True)\n","      correct = pred.eq(y.view_as(pred)).sum().item()\n","      total_correct += correct\n","      total_loss += loss_val\n","      # print(f\"train loss: {loss_val:>7f}   train accuracy: {correct / BATCH_SIZE:>7f}   [batch: {batch + 1:>3d}/{(size // BATCH_SIZE) + 1:>3d}]\")      \n","    print(f\"\\nepoch avg train loss: {total_loss / ((size // BATCH_SIZE) + 1):>7f}   epoch avg train accuracy: {total_correct / size:>7f}\")\n","      \n","def eval_loop(dataloader, model):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  with torch.no_grad():\n","    total_correct = 0\n","    for x, y in dataloader:\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      out = model(x)\n","      y, out = y.to(\"cpu\"), out.to(\"cpu\")\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    accuracy = total_correct / size\n","    return accuracy\n"],"metadata":{"id":"V5PBJO-lrBH8","executionInfo":{"status":"ok","timestamp":1664479624059,"user_tz":420,"elapsed":6,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OesVurZASnQW"},"outputs":[],"source":["# define methods for unpacking Quickdraw .bin files\n","def unpack_drawing(file_handle):\n","  file_handle.read(15)\n","  n_strokes, = unpack('H', file_handle.read(2))\n","  image = []\n","  for i in range(n_strokes):\n","      n_points, = unpack('H', file_handle.read(2))\n","      fmt = str(n_points) + 'B'\n","      x = unpack(fmt, file_handle.read(n_points))\n","      y = unpack(fmt, file_handle.read(n_points))\n","      image.append((x, y))\n","\n","  return image\n","\n","\n","def unpack_drawings(filename):\n","  imageset = []\n","  with open(filename, 'rb') as f:\n","      while True:\n","          try:\n","              imageset.append(unpack_drawing(f))\n","          except struct.error:\n","              break\n","  return imageset\n","\n","train_dir = '/content/drive/My Drive/Fourier/Quickdraw Dataset Small/Train/'\n","test_dir = '/content/drive/My Drive/Fourier/Quickdraw Dataset Small/Test/'\n","train_imgs = []\n","test_imgs = []\n","train_nums = []\n","test_nums = []\n","# list_of_classes = [\"arm\", \"brain\", \"circle\", \"ear\", \"elbow\", \"eye\", \n","#                    \"face\", \"finger\", \"foot\", \"hand\", \"hexagon\", \"knee\", \n","#                    \"leg\", \"line\", \"mouth\", \"nose\", \"octagon\", \n","#                    'skull', 'square', 'squiggle', 'star', 'toe', 'tooth', \n","#                    'triangle', 'zigzag']\n","list_of_classes = [\"aircraft carrier\", \"airplane\", \"alarm clock\", \"ambulance\", \n","                   \"angel\", \"ant\", \"anvil\", \"apple\", \"arm\", \"asparagus\", \"axe\", \n","                   \"backpack\", \"banana\", \"bandage\", \"barn\", \"baseball bat\", \n","                   \"baseball\", \"basket\", \"basketball\", \"bathtub\", \"beach\", \"bear\", \n","                   \"beard\", \"bed\", \"bee\"]"]},{"cell_type":"code","source":["# load dataset\n","for item in list_of_classes:\n","  train_folder = train_dir + item + '.bin'\n","  test_folder = test_dir + item + '.bin'\n","  train_drawings = unpack_drawings(train_folder)\n","  train_imgs += train_drawings\n","  train_nums.append(len(train_drawings))\n","  test_drawings = unpack_drawings(test_folder)\n","  test_imgs += test_drawings\n","  test_nums.append(len(test_drawings))"],"metadata":{"id":"EWDVtZKfd4Uk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DEVICE = \"cpu\"\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","\n","def get_confusion_mat(dataloader, model):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  conf_mat = np.zeros((NUM_CLASSES, NUM_CLASSES))\n","  with torch.no_grad():\n","    total_correct = 0\n","    for x, y in dataloader:\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      out = model(x)\n","      y, out = y.to(\"cpu\"), out.to(\"cpu\")\n","      pred = out.argmax(dim=1, keepdim=True)\n","      y = y.view_as(pred)\n","      total_correct += pred.eq(y).sum().item()\n","      y, pred = y.numpy(), pred.numpy()\n","      indices = np.concatenate((y, pred), axis=1)\n","      for i in range(indices.shape[0]):\n","        conf_mat[indices[i, 0], indices[i, 1]] += 1\n","\n","    accuracy = total_correct / size\n","    print(f\"test accuracy: {accuracy:>7f}\")\n","    return conf_mat\n","\n","eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","model = MLP()\n","checkpoint = torch.load(LOAD_PATH, map_location=torch.device(DEVICE))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","\n","random.seed(RAND_SEED)\n","conf_mat = get_confusion_mat(dataloader=eval_loader,model=model)\n","conf_mat_norm = conf_mat * (255 / 100)\n","cv2_imshow(conf_mat_norm)\n","\n","diag = np.diagonal(conf_mat)\n","sums = np.asarray(test_nums)\n","accuracies = diag / sums\n","acc_sorted_idxs = np.argsort(accuracies)\n","for i in range(NUM_CLASSES):\n","  print(list_of_classes[acc_sorted_idxs[i]] + \" accuracy \" + str(accuracies[acc_sorted_idxs[i]]))\n","\n","print(\"\\n\")\n","\n","diag_mat = np.multiply(np.identity(NUM_CLASSES), conf_mat)\n","conf_mat_nodiag = conf_mat - diag_mat\n","conf_mat_sorted = np.argsort(conf_mat_nodiag, axis=None)\n","for i in range(1, 6):\n","  print(\"class \" + list_of_classes[conf_mat_sorted[-i] // NUM_CLASSES] + \" misclassified as \" + list_of_classes[conf_mat_sorted[-i] % NUM_CLASSES])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":615},"id":"ZZ82isB3s8-L","executionInfo":{"status":"ok","timestamp":1663271573231,"user_tz":420,"elapsed":20688,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}},"outputId":"8fede2a0-6818-4dbc-e1f0-eff9fe1115e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test accuracy: 0.563826\n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=L size=25x25 at 0x7F3D191A4C90>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABkAAAAZCAAAAADhgtq/AAABOElEQVR4nEWSMWodQRAFi4JHQzOwLCyCD0awGIzCH+oGvoFDJQ6V+QKODeYnBoMOYDBOdAYlynUI38PBrORsBqbfVFc3f4DCnMIwBggKeMfmvogA6jky5vVROV6BtxABsPzdnTQJpAhAgJb6QjHgg9AFZY0GToRvYwZwEwY68zZDHmYyW3j/mmahcElTpptWRlNcD9jVT5LYVwr0ihMFyMtxKDr2wT3/OEfpC1dHb6NwN73Cx7WygCvdyioGXGD7fN07kEw5AQ9M/nr4A/FE7B5Akx89TQuUxJAWG78rwe0E1rZE0K1Qv1riIrBRjhtmfsuFHHOYbHOyWO3LwVAr9FTRSCP3ycZ5Fqqp/9VPWZBFXTRNKjIoKvdrGooaBILAqu9Mfr56nttRkFVQ65k3GTVXp4g7w/r1D9XwGEi+yfRHAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["hexagon accuracy 0.19\n","knee accuracy 0.28\n","foot accuracy 0.34\n","brain accuracy 0.37\n","leg accuracy 0.39\n","squiggle accuracy 0.42\n","toe accuracy 0.42424242424242425\n","elbow accuracy 0.45\n","octagon accuracy 0.5\n","eye accuracy 0.54\n","nose accuracy 0.55\n","finger accuracy 0.56\n","skull accuracy 0.56\n","mouth accuracy 0.58\n","tooth accuracy 0.59\n","face accuracy 0.6\n","zigzag accuracy 0.65\n","ear accuracy 0.66\n","arm accuracy 0.67\n","circle accuracy 0.69\n","star accuracy 0.76\n","triangle accuracy 0.78\n","square accuracy 0.82\n","hand accuracy 0.82\n","line accuracy 0.9\n","\n","\n","class hexagon misclassified as octagon\n","class circle misclassified as octagon\n","class brain misclassified as skull\n","class squiggle misclassified as zigzag\n","class eye misclassified as mouth\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_fourier_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_fourier_loader = DataLoader(eval_fourier_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = MLP()\n","# checkpoint = torch.load(LOAD_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","print(\"\\n\\n\\nFourier order is: \"+str(FOURIER_ORDER)+\"\\n\\n\\n\")\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","eval_loop(dataloader=test_loader,model=model)\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25-2 MLP vector single-wide.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_fourier_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"id":"RuK0bk7HiafW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_fourier_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_fourier_loader = DataLoader(eval_fourier_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = MLP()\n","# checkpoint = torch.load(LOAD_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","print(\"\\n\\n\\nFourier order is: \"+str(FOURIER_ORDER)+\"\\n\\n\\n\")\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","eval_loop(dataloader=test_loader,model=model)\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 MLP vector single-wide.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_fourier_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0rHAgQNDPQO","executionInfo":{"status":"ok","timestamp":1663262590549,"user_tz":420,"elapsed":1884624,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}},"outputId":"6e5af51b-2125-40f8-ef92-602a355d815f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","Fourier order is: 10\n","\n","\n","\n","Epoch 1\n","\n","loss: 3.217961  [  512/25000]\n","loss: 2.748842  [10752/25000]\n","loss: 2.314478  [20992/25000]\n","\n","epoch avg train loss: 2.692370   epoch avg train accuracy: 0.211440\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 2.283867  [  512/25000]\n","loss: 2.192767  [10752/25000]\n","loss: 1.948175  [20992/25000]\n","\n","epoch avg train loss: 2.102938   epoch avg train accuracy: 0.367840\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 1.876649  [  512/25000]\n","loss: 1.931707  [10752/25000]\n","loss: 1.787562  [20992/25000]\n","\n","epoch avg train loss: 1.832597   epoch avg train accuracy: 0.450880\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 1.742038  [  512/25000]\n","loss: 1.660178  [10752/25000]\n","loss: 1.667130  [20992/25000]\n","\n","epoch avg train loss: 1.622900   epoch avg train accuracy: 0.511000\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 1.504452  [  512/25000]\n","loss: 1.453395  [10752/25000]\n","loss: 1.340576  [20992/25000]\n","\n","epoch avg train loss: 1.450292   epoch avg train accuracy: 0.561040\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 1.346474  [  512/25000]\n","loss: 1.194759  [10752/25000]\n","loss: 1.277427  [20992/25000]\n","\n","epoch avg train loss: 1.320480   epoch avg train accuracy: 0.595000\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 1.205867  [  512/25000]\n","loss: 1.170698  [10752/25000]\n","loss: 1.243047  [20992/25000]\n","\n","epoch avg train loss: 1.202629   epoch avg train accuracy: 0.627360\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 1.090928  [  512/25000]\n","loss: 1.042233  [10752/25000]\n","loss: 1.122634  [20992/25000]\n","\n","epoch avg train loss: 1.089085   epoch avg train accuracy: 0.663120\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 1.031936  [  512/25000]\n","loss: 1.052645  [10752/25000]\n","loss: 0.925966  [20992/25000]\n","\n","epoch avg train loss: 0.990125   epoch avg train accuracy: 0.687520\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.901987  [  512/25000]\n","loss: 0.864899  [10752/25000]\n","loss: 0.822740  [20992/25000]\n","\n","epoch avg train loss: 0.880220   epoch avg train accuracy: 0.722800\n","\n","-------------------------------\n","\n","0.5638255302120849\n","1.1102230246251565e-16\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_fourier_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_fourier_loader = DataLoader(eval_fourier_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = MLP()\n","# checkpoint = torch.load(LOAD_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","print(\"\\n\\n\\nFourier order is: \"+str(FOURIER_ORDER)+\"\\n\\n\\n\")\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","eval_loop(dataloader=test_loader,model=model)\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset MLP vector single-wide.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_fourier_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"id":"JoP5gNZYE5pF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663219739809,"user_tz":420,"elapsed":2219067,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"75ec414a-77f9-44a0-ef2e-f47b8ec90b1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","Fourier order is: 10\n","\n","\n","\n","Epoch 1\n","\n","loss: 3.330191  [  512/28000]\n","loss: 2.760625  [10752/28000]\n","loss: 2.461224  [20992/28000]\n","\n","epoch avg train loss: 2.749492   epoch avg train accuracy: 0.209893\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 2.394397  [  512/28000]\n","loss: 2.193367  [10752/28000]\n","loss: 2.275110  [20992/28000]\n","\n","epoch avg train loss: 2.171338   epoch avg train accuracy: 0.359036\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 2.088549  [  512/28000]\n","loss: 1.925457  [10752/28000]\n","loss: 1.866967  [20992/28000]\n","\n","epoch avg train loss: 1.900197   epoch avg train accuracy: 0.444000\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 1.668187  [  512/28000]\n","loss: 1.670239  [10752/28000]\n","loss: 1.681529  [20992/28000]\n","\n","epoch avg train loss: 1.696758   epoch avg train accuracy: 0.499286\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 1.543532  [  512/28000]\n","loss: 1.510883  [10752/28000]\n","loss: 1.487572  [20992/28000]\n","\n","epoch avg train loss: 1.532818   epoch avg train accuracy: 0.543107\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 1.421022  [  512/28000]\n","loss: 1.376001  [10752/28000]\n","loss: 1.471875  [20992/28000]\n","\n","epoch avg train loss: 1.395469   epoch avg train accuracy: 0.579179\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 1.158848  [  512/28000]\n","loss: 1.254780  [10752/28000]\n","loss: 1.196745  [20992/28000]\n","\n","epoch avg train loss: 1.275037   epoch avg train accuracy: 0.612643\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 1.067919  [  512/28000]\n","loss: 1.155486  [10752/28000]\n","loss: 1.257002  [20992/28000]\n","\n","epoch avg train loss: 1.155261   epoch avg train accuracy: 0.647893\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 1.076904  [  512/28000]\n","loss: 1.021906  [10752/28000]\n","loss: 1.105852  [20992/28000]\n","\n","epoch avg train loss: 1.042815   epoch avg train accuracy: 0.679643\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.884018  [  512/28000]\n","loss: 0.924618  [10752/28000]\n","loss: 0.888271  [20992/28000]\n","\n","epoch avg train loss: 0.945575   epoch avg train accuracy: 0.707000\n","\n","-------------------------------\n","\n","0.5326902465166133\n","2.220446049250313e-16\n"]}]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1HmEE3jGUpn2AzNnSdBfhtm74OSHAmt0o","timestamp":1663194740604},{"file_id":"1owTDTec1_uglqFzHWQQKQbfPBG9Ge_Ep","timestamp":1649121474527}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}