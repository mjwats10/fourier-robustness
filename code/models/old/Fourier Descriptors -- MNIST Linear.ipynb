{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14834,"status":"ok","timestamp":1651786406651,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"},"user_tz":420},"id":"wDjjZFaGNZXV","outputId":"78863656-1537-4f00-a40c-cb563a54618f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyefd\n","  Downloading pyefd-1.6.0-py2.py3-none-any.whl (7.7 kB)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyefd) (1.21.6)\n","Installing collected packages: pyefd\n","Successfully installed pyefd-1.6.0\n"]}],"source":["import torch\n","from torch import nn\n","from torchvision import datasets\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","import random\n","import cv2\n","import numpy as np\n","!pip install pyefd\n","import pyefd\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"code","source":["# Env vars\n","torch.use_deterministic_algorithms(True) # to ensure reproduceability\n","ROOT_DIR = \"/mnist\"\n","RAND_SEED = 0\n","DEVICE = \"cpu\"\n","\n","# training hyperparameters\n","NUM_CLASSES = 10\n","EPOCHS = 10\n","#FOURIER_ORDER = 10\n","LEARNING_RATE = 1e-3\n","BATCH_SIZE = 500\n","NUM_TRAIN_BATCHES = 60000 // BATCH_SIZE\n","NUM_VAL_BATCHES = 10000 // BATCH_SIZE\n","loss_fn = nn.CrossEntropyLoss()\n","\n","\n","# function to ensure deterministic worker re-seeding for reproduceability\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)"],"metadata":{"id":"rTgcmhsuUBVx","executionInfo":{"status":"ok","timestamp":1651786406651,"user_tz":420,"elapsed":6,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZSpVSjCyUPb6"},"source":["Section 1: Fourier Descriptors through linear classifier"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"iJz6slq1shwv","executionInfo":{"status":"ok","timestamp":1651787311395,"user_tz":420,"elapsed":377,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}}},"outputs":[],"source":["# mlp taking array of normalized fourier descriptors\n","class LinearClassifierFourier(nn.Module):\n","    def __init__(self):\n","        super(LinearClassifierFourier, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.mlp = nn.Sequential(\n","        nn.Linear(FOURIER_ORDER*4, 512),\n","        nn.ReLU(),\n","        nn.Linear(512,512),\n","        nn.ReLU(),\n","        nn.Linear(512,512),\n","        nn.ReLU(),\n","        nn.Linear(512,NUM_CLASSES))\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        out = self.mlp(x)\n","        return out\n","\n","# train_loop is called once each epoch and trains model on training set\n","def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train() # put the model in train mode\n","    total_loss = 0\n","    total_correct = 0\n","    # for each batch in the training set compute loss and update model parameters\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation to update model parameters\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print current training metrics for user\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","        '''\n","        pred = pred.argmax(dim=1, keepdim=True)\n","        correct = pred.eq(y.view_as(pred)).sum().item()\n","        total_correct += correct\n","        total_loss += loss.item()\n","        #print(f\"train loss: {loss.item():>7f}   train accuracy: {correct / BATCH_SIZE:>7f}   [batch: {batch + 1:>3d}/{NUM_TRAIN_BATCHES:>3d}]\")      \n","    print(f\"\\nepoch avg train loss: {total_loss / NUM_TRAIN_BATCHES:>7f}   epoch avg train accuracy: {total_correct / (NUM_TRAIN_BATCHES * BATCH_SIZE):>7f}\")\n","      '''\n","\n","# test_loop evaluates model performance on test set with affine transformations\n","def test_loop():\n","  model.eval()  # put model in evalutation mode\n","  with torch.no_grad(): # tensors do not accumulate gradients since not training\n","    total_correct = 0\n","    # run each batch from the test set loader through the model\n","    for X, y in test_fourier_loader:\n","      X, y = X.to(DEVICE), y.to(DEVICE)\n","\n","      # for a given batch, find the model's prediction out.argmax\n","      # then see if this prediction is correct or not (pred.eq = 1 or 0)\n","      out = model(X)\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    # finally print test accuracy for user\n","    accuracy = total_correct / (NUM_VAL_BATCHES * BATCH_SIZE)\n","    print(f\"test accuracy with affine transformations: {accuracy:>7f}\")\n","\n","# eval_loop evaluates model performance on test set with no transformations\n","def eval_loop():\n","  model.eval()  # put model in evalutation mode\n","  with torch.no_grad(): # tensors do not accumulate gradients since not training\n","    total_correct = 0\n","    # run each batch from the eval set loader through the model\n","    for X, y in eval_fourier_loader:\n","      X, y = X.to(DEVICE), y.to(DEVICE)\n","\n","      # for a given batch, find the model's prediction out.argmax\n","      # then see if this prediction is correct or not (pred.eq = 1 or 0)\n","      out = model(X)\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    # finally print eval accuracy for user\n","    accuracy = total_correct / (NUM_VAL_BATCHES * BATCH_SIZE)\n","    print(f\"test accuracy: {accuracy:>7f}\")\n","\n","\n","\n","# transform MNIST images - take PIL image, return torch tensor of Fourier descriptors\n","def fourier_transform_train(img):\n","  img = np.asarray(img) # convert PIL image to numpy array for openCV\n","  ret, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) # binarize image\n","  contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # find outer contour of objects (digit) in image\n","\n","  # since some images have artifacts disconnected from the digit, extract only\n","  # largest contour from the contour list (this should be the digit)\n","  largest_size = 0\n","  largest_index = 0\n","  for i, contour in enumerate(contours):\n","      if len(contour) > largest_size:\n","        largest_size = len(contour)\n","        largest_index = i\n","  contour = contours[largest_index]\n","\n","  # use Pyefd to extract normalized Fourier descriptors then convert from numpy\n","  # array to torch tensor of dtype=float\n","  coeffs = pyefd.elliptic_fourier_descriptors(np.squeeze(contour), order=FOURIER_ORDER, normalize=True)\n","  return torch.from_numpy(coeffs).float()\n","\n","\n","# same as fourier_transform_train, but for test set -- adds affine transforms\n","def fourier_transform_test(img):\n","  img = np.asarray(img) # convert PIL image to numpy array for openCV\n","  ret, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)  # binarize image\n","  contours, hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # find outer contour of objects (digit) in image\n","\n","  # since some images have artifacts disconnected from the digit, extract only\n","  # largest contour from the contour list (this should be the digit)\n","  largest_size = 0\n","  largest_index = 0\n","  for i, contour in enumerate(contours):\n","      if len(contour) > largest_size:\n","        largest_size = len(contour)\n","        largest_index = i\n","  contour = contours[largest_index]\n","\n","  # randomly select from 4 possible rotations and randomly select deltaX and\n","  # deltaY for translations in the range of (-3,3)\n","  rotations = [0, 90, 180, 270]\n","  angle = rotations[random.randint(0, len(rotations) - 1)]\n","  transY = random.randint(-3,3)\n","  transX = random.randint(-3,3)\n","\n","  # linear algebra to apply randomly generated transformations to the digit contour\n","  theta = np.radians(angle)\n","  c, s = np.round(np.cos(theta)), np.round(np.sin(theta))\n","  R = np.array(((c, -s), (s, c)))\n","  trans = np.array((transX, transY))\n","  contourT = [np.expand_dims(np.transpose(np.dot(R, np.transpose(np.squeeze(contour)))) + trans, 1).astype(np.int32)]\n","\n","  # use Pyefd to extract normalized Fourier descriptors then convert from numpy\n","  # array to torch tensor of dtype=float\n","  coeffs = pyefd.elliptic_fourier_descriptors(np.squeeze(contourT), order=FOURIER_ORDER, normalize=True)\n","  return torch.from_numpy(coeffs).float()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNfLxZDAowRD","outputId":"ecccdddc-2247-4f21-a4d5-436160542f64","executionInfo":{"status":"ok","timestamp":1651789586055,"user_tz":420,"elapsed":2246462,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n"," Fourier order is:1\n","\n","\n","\n","Epoch 1\n","\n","loss: 2.302356  [    0/60000]\n","loss: 1.847657  [50000/60000]\n","test accuracy: 0.269900\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.804473  [    0/60000]\n","loss: 1.883050  [50000/60000]\n","test accuracy: 0.270300\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 1.854061  [    0/60000]\n","loss: 1.872818  [50000/60000]\n","test accuracy: 0.274800\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 1.861413  [    0/60000]\n","loss: 1.843984  [50000/60000]\n","test accuracy: 0.267400\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 1.907628  [    0/60000]\n","loss: 1.850693  [50000/60000]\n","test accuracy: 0.275100\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 1.792173  [    0/60000]\n","loss: 1.823873  [50000/60000]\n","test accuracy: 0.281200\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 1.842126  [    0/60000]\n","loss: 1.865112  [50000/60000]\n","test accuracy: 0.274200\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 1.842466  [    0/60000]\n","loss: 1.811571  [50000/60000]\n","test accuracy: 0.268400\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 1.847665  [    0/60000]\n","loss: 1.860963  [50000/60000]\n","test accuracy: 0.273000\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 1.843559  [    0/60000]\n","loss: 1.879709  [50000/60000]\n","test accuracy: 0.275200\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.275200\n","\n","\n","\n"," Fourier order is:2\n","\n","\n","\n","Epoch 1\n","\n","loss: 2.304281  [    0/60000]\n","loss: 0.800476  [50000/60000]\n","test accuracy: 0.785100\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.672826  [    0/60000]\n","loss: 0.628419  [50000/60000]\n","test accuracy: 0.816300\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.595680  [    0/60000]\n","loss: 0.612980  [50000/60000]\n","test accuracy: 0.830000\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.517589  [    0/60000]\n","loss: 0.565008  [50000/60000]\n","test accuracy: 0.831000\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.626242  [    0/60000]\n","loss: 0.511149  [50000/60000]\n","test accuracy: 0.836200\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.450846  [    0/60000]\n","loss: 0.425891  [50000/60000]\n","test accuracy: 0.838900\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.437500  [    0/60000]\n","loss: 0.491340  [50000/60000]\n","test accuracy: 0.839800\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.436844  [    0/60000]\n","loss: 0.463454  [50000/60000]\n","test accuracy: 0.842500\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.454397  [    0/60000]\n","loss: 0.441464  [50000/60000]\n","test accuracy: 0.840800\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.394714  [    0/60000]\n","loss: 0.475413  [50000/60000]\n","test accuracy: 0.845200\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.845200\n","\n","\n","\n"," Fourier order is:3\n","\n","\n","\n","Epoch 1\n","\n","loss: 2.302820  [    0/60000]\n","loss: 0.391643  [50000/60000]\n","test accuracy: 0.892900\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.380243  [    0/60000]\n","loss: 0.340195  [50000/60000]\n","test accuracy: 0.918400\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.288950  [    0/60000]\n","loss: 0.313721  [50000/60000]\n","test accuracy: 0.926000\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.243192  [    0/60000]\n","loss: 0.267887  [50000/60000]\n","test accuracy: 0.934500\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.303363  [    0/60000]\n","loss: 0.201256  [50000/60000]\n","test accuracy: 0.937900\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.155613  [    0/60000]\n","loss: 0.191688  [50000/60000]\n","test accuracy: 0.938400\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.165423  [    0/60000]\n","loss: 0.217197  [50000/60000]\n","test accuracy: 0.937500\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.128919  [    0/60000]\n","loss: 0.129550  [50000/60000]\n","test accuracy: 0.943600\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.147957  [    0/60000]\n","loss: 0.158934  [50000/60000]\n","test accuracy: 0.944600\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.173427  [    0/60000]\n","loss: 0.185596  [50000/60000]\n","test accuracy: 0.945700\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.945700\n","\n","\n","\n"," Fourier order is:4\n","\n","\n","\n","Epoch 1\n","\n","loss: 2.304059  [    0/60000]\n","loss: 0.339027  [50000/60000]\n","test accuracy: 0.910700\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.324714  [    0/60000]\n","loss: 0.312789  [50000/60000]\n","test accuracy: 0.936000\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.249019  [    0/60000]\n","loss: 0.299917  [50000/60000]\n","test accuracy: 0.945500\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.189029  [    0/60000]\n","loss: 0.236509  [50000/60000]\n","test accuracy: 0.949400\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.228801  [    0/60000]\n","loss: 0.144399  [50000/60000]\n","test accuracy: 0.952000\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.119761  [    0/60000]\n","loss: 0.138184  [50000/60000]\n","test accuracy: 0.954900\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.108024  [    0/60000]\n","loss: 0.163151  [50000/60000]\n","test accuracy: 0.957300\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.086151  [    0/60000]\n","loss: 0.107954  [50000/60000]\n","test accuracy: 0.956000\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.114485  [    0/60000]\n","loss: 0.120629  [50000/60000]\n","test accuracy: 0.959100\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.108049  [    0/60000]\n","loss: 0.148569  [50000/60000]\n","test accuracy: 0.958400\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.958400\n","\n","\n","\n"," Fourier order is:5\n","\n","\n","\n","Epoch 1\n","\n","loss: 2.304619  [    0/60000]\n","loss: 0.327430  [50000/60000]\n","test accuracy: 0.911900\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.314615  [    0/60000]\n","loss: 0.288235  [50000/60000]\n","test accuracy: 0.941800\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.230706  [    0/60000]\n","loss: 0.280844  [50000/60000]\n","test accuracy: 0.949400\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.177766  [    0/60000]\n","loss: 0.232990  [50000/60000]\n","test accuracy: 0.953600\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.219482  [    0/60000]\n","loss: 0.138651  [50000/60000]\n","test accuracy: 0.953800\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.105711  [    0/60000]\n","loss: 0.149092  [50000/60000]\n","test accuracy: 0.956400\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.100605  [    0/60000]\n","loss: 0.149592  [50000/60000]\n","test accuracy: 0.958500\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.076753  [    0/60000]\n","loss: 0.103082  [50000/60000]\n","test accuracy: 0.961500\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.086927  [    0/60000]\n","loss: 0.109779  [50000/60000]\n","test accuracy: 0.960900\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.102945  [    0/60000]\n","loss: 0.124902  [50000/60000]\n","test accuracy: 0.962800\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.962800\n","\n","\n","\n"," Fourier order is:6\n","\n","\n","\n","Epoch 1\n","\n","loss: 2.302710  [    0/60000]\n","loss: 0.326306  [50000/60000]\n","test accuracy: 0.912200\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.318026  [    0/60000]\n","loss: 0.289093  [50000/60000]\n","test accuracy: 0.940100\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.230759  [    0/60000]\n","loss: 0.286837  [50000/60000]\n","test accuracy: 0.949700\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.183134  [    0/60000]\n","loss: 0.226908  [50000/60000]\n","test accuracy: 0.952400\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.229929  [    0/60000]\n","loss: 0.131233  [50000/60000]\n","test accuracy: 0.956700\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.102937  [    0/60000]\n","loss: 0.144961  [50000/60000]\n","test accuracy: 0.958800\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.106654  [    0/60000]\n","loss: 0.144104  [50000/60000]\n","test accuracy: 0.960500\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.075142  [    0/60000]\n","loss: 0.093712  [50000/60000]\n","test accuracy: 0.961000\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.086555  [    0/60000]\n","loss: 0.108045  [50000/60000]\n","test accuracy: 0.962300\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.106741  [    0/60000]\n","loss: 0.119442  [50000/60000]\n","test accuracy: 0.963400\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.963400\n"]}],"source":["# test values for fourier series order in the range (1, 8)\n","for FOURIER_ORDER in range(1, 8):\n","  # seed RNGs\n","  torch.manual_seed(RAND_SEED)\n","  random.seed(RAND_SEED)\n","\n","  # create train, eval, and test datasets\n","  train_fourier_data = datasets.MNIST(root=ROOT_DIR, train=True, download=True, transform=fourier_transform_train) # train data\n","  eval_fourier_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=fourier_transform_train) # test data WITHOUT affine transforms\n","  test_fourier_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=fourier_transform_test) # test data WITH affine transforms\n","\n","\n","  # create generator for dataloaders and create dataloaders for each dataset\n","  g = torch.Generator()\n","  g.manual_seed(RAND_SEED)\n","  train_fourier_loader = DataLoader(train_fourier_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","  eval_fourier_loader = DataLoader(eval_fourier_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","  test_fourier_loader = DataLoader(test_fourier_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","\n","  # initalize model object and load model parameters into optimizer\n","  model = LinearClassifierFourier()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","  print(\"\\n\\n\\n Fourier order is:\"+str(FOURIER_ORDER)+\"\\n\\n\\n\")  \n","\n","  # train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","  for i in range(EPOCHS):\n","      print(\"Epoch \" + str(i + 1) + \"\\n\")\n","      train_loop(dataloader=train_fourier_loader,model=model,loss_fn=loss_fn,optimizer=optimizer)\n","      eval_loop()\n","      print(\"\\n-------------------------------\\n\")\n","  \n","  test_loop()\n","    "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6670e7b7-0ea1-488b-cfcd-f454604e4981","executionInfo":{"status":"ok","timestamp":1651790127274,"user_tz":420,"elapsed":467493,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"id":"xn0XiI10VVII"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n"," Fourier order is:7\n","\n","\n","\n","Epoch 1\n","\n","loss: 2.300968  [    0/60000]\n","loss: 0.329676  [50000/60000]\n","test accuracy: 0.912300\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.317363  [    0/60000]\n","loss: 0.285217  [50000/60000]\n","test accuracy: 0.939700\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.243225  [    0/60000]\n","loss: 0.278820  [50000/60000]\n","test accuracy: 0.949000\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.182522  [    0/60000]\n","loss: 0.226933  [50000/60000]\n","test accuracy: 0.954300\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.206702  [    0/60000]\n","loss: 0.128830  [50000/60000]\n","test accuracy: 0.954900\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.098069  [    0/60000]\n","loss: 0.125930  [50000/60000]\n","test accuracy: 0.958900\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.097331  [    0/60000]\n","loss: 0.149273  [50000/60000]\n","test accuracy: 0.960900\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.071730  [    0/60000]\n","loss: 0.095113  [50000/60000]\n","test accuracy: 0.962300\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.078527  [    0/60000]\n","loss: 0.104867  [50000/60000]\n","test accuracy: 0.962900\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.101318  [    0/60000]\n","loss: 0.122361  [50000/60000]\n","test accuracy: 0.962000\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.962000\n"]}],"source":["# test values for fourier series order in the range (1, 8)\n","for FOURIER_ORDER in range(8, 10):\n","  # seed RNGs\n","  torch.manual_seed(RAND_SEED)\n","  random.seed(RAND_SEED)\n","\n","  # create train, eval, and test datasets\n","  train_fourier_data = datasets.MNIST(root=ROOT_DIR, train=True, download=True, transform=fourier_transform_train) # train data\n","  eval_fourier_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=fourier_transform_train) # test data WITHOUT affine transforms\n","  test_fourier_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=fourier_transform_test) # test data WITH affine transforms\n","\n","\n","  # create generator for dataloaders and create dataloaders for each dataset\n","  g = torch.Generator()\n","  g.manual_seed(RAND_SEED)\n","  train_fourier_loader = DataLoader(train_fourier_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","  eval_fourier_loader = DataLoader(eval_fourier_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","  test_fourier_loader = DataLoader(test_fourier_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","\n","  # initalize model object and load model parameters into optimizer\n","  model = LinearClassifierFourier()\n","  optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","  print(\"\\n\\n\\n Fourier order is:\"+str(FOURIER_ORDER)+\"\\n\\n\\n\")  \n","\n","  # train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","  for i in range(EPOCHS):\n","      print(\"Epoch \" + str(i + 1) + \"\\n\")\n","      train_loop(dataloader=train_fourier_loader,model=model,loss_fn=loss_fn,optimizer=optimizer)\n","      eval_loop()\n","      print(\"\\n-------------------------------\\n\")\n","  \n","  test_loop()\n","    "]},{"cell_type":"markdown","metadata":{"id":"Zj7ducsDUaBe"},"source":["Section 2: Original images through linear classifier (to compare)\n","train model on MNIST \n","without getting the fourier descriptors \n","return the original image \n","\n","https://pytorch.org/vision/stable/transforms.html"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"kIqC-dltRuq0","executionInfo":{"status":"ok","timestamp":1651790233104,"user_tz":420,"elapsed":182,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}}},"outputs":[],"source":["# mlp taking mnist images\n","class LinearClassifierOriginal(nn.Module):\n","    def __init__(self):\n","        super(LinearClassifierOriginal, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.mlp = nn.Sequential(\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512,512),\n","        nn.ReLU(),\n","        nn.Linear(512,512),\n","        nn.ReLU(),\n","        nn.Linear(512,NUM_CLASSES))\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        out = self.mlp(x)\n","        return out\n","\n","# Define transformation(s) to be applied to dataset-\n","transforms_norm = transforms.Compose(\n","      [\n","          transforms.ToTensor(),\n","          transforms.Normalize(mean = (0.1307,), std = (0.3081,)), # MNIST mean and stdev\n","          \n","      ]\n","  )\n","\n","# transform functions - take PIL image, return img as 1x28x28 torch tensor\n","# normalize each image by mean and sd (MNIST): https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457\n","# convert normalized image to torch tensor and return \n","def original_transform_train(img):  \n","  # retrun normalized image\n","  return transforms_norm(img) \n","\n","# add rotations and translations at test time\n","# normalize each image by mean and sd (MNIST)\n","# apply random rotation and translations (use pytorch methods): https://pytorch.org/vision/stable/generated/torchvision.transforms.RandomRotation.html#torchvision.transforms.RandomRotation\n","# OR https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.functional.affine\n","# \n","# return torch tensor\n","def original_transform_test(img):\n","    img = transforms_norm(img)\n","    angle=((random.random())*60)-30\n","    \n","    transY = random.randint(-3,3)\n","    transX = random.randint(-3,3)\n","    new_img = transforms.functional.affine(img,angle,[transX,transY],1,0) \n","    return new_img\n","#...........\n","\n","# train_loop is called once each epoch and trains model on training set\n","def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train() # put the model in train mode\n","    total_loss = 0\n","    total_correct = 0\n","    # for each batch in the training set compute loss and update model parameters\n","    for batch, (X, y) in enumerate(dataloader):\n","        # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation to update model parameters\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print current training metrics for user\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","# test_loop evaluates model performance on test set with affine transformations\n","def test_loop():\n","  model.eval()  # put model in evalutation mode\n","  with torch.no_grad(): # tensors do not accumulate gradients since not training\n","    total_correct = 0\n","    # run each batch from the test set loader through the model\n","    for X, y in test_original_loader:\n","      X, y = X.to(DEVICE), y.to(DEVICE)\n","\n","      # for a given batch, find the model's prediction out.argmax\n","      # then see if this prediction is correct or not (pred.eq = 1 or 0)\n","      out = model(X)\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    # finally print test accuracy for user\n","    accuracy = total_correct / (NUM_VAL_BATCHES * BATCH_SIZE)\n","    print(f\"test accuracy with affine transformations: {accuracy:>7f}\")\n","\n","# eval_loop evaluates model performance on test set with no transformations\n","def eval_loop():\n","  model.eval()  # put model in evalutation mode\n","  with torch.no_grad(): # tensors do not accumulate gradients since not training\n","    total_correct = 0\n","    # run each batch from the eval set loader through the model\n","    for X, y in eval_original_loader:\n","      X, y = X.to(DEVICE), y.to(DEVICE)\n","\n","      # for a given batch, find the model's prediction out.argmax\n","      # then see if this prediction is correct or not (pred.eq = 1 or 0)\n","      out = model(X)\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    # finally print eval accuracy for user\n","    accuracy = total_correct / (NUM_VAL_BATCHES * BATCH_SIZE)\n","    print(f\"test accuracy: {accuracy:>7f}\")\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ULXB08VAVIEW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651790447921,"user_tz":420,"elapsed":201872,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"c5dc0186-4863-4def-f1b5-e0f668f66deb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 2.300539  [    0/60000]\n","loss: 0.185107  [50000/60000]\n","test accuracy: 0.956700\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.121919  [    0/60000]\n","loss: 0.099608  [50000/60000]\n","test accuracy: 0.970300\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.063124  [    0/60000]\n","loss: 0.093923  [50000/60000]\n","test accuracy: 0.974500\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.071086  [    0/60000]\n","loss: 0.049891  [50000/60000]\n","test accuracy: 0.976600\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.055841  [    0/60000]\n","loss: 0.022989  [50000/60000]\n","test accuracy: 0.980000\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.020021  [    0/60000]\n","loss: 0.039589  [50000/60000]\n","test accuracy: 0.979200\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.020829  [    0/60000]\n","loss: 0.016611  [50000/60000]\n","test accuracy: 0.979200\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.013227  [    0/60000]\n","loss: 0.016865  [50000/60000]\n","test accuracy: 0.978600\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.018315  [    0/60000]\n","loss: 0.019721  [50000/60000]\n","test accuracy: 0.980200\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.010174  [    0/60000]\n","loss: 0.029847  [50000/60000]\n","test accuracy: 0.979500\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.594300\n"]}],"source":["# TODO: create original image dataset\n","# TODO: create generators for original dataset\n","# Env vars\n","torch.use_deterministic_algorithms(True) # to ensure reproduceability\n","ROOT_DIR = \"/mnist\"\n","RAND_SEED = 0\n","DEVICE = \"cpu\"\n","\n","# training hyperparameters\n","NUM_CLASSES = 10\n","EPOCHS = 10\n","#FOURIER_ORDER = 10\n","LEARNING_RATE = 1e-3\n","BATCH_SIZE = 500\n","NUM_TRAIN_BATCHES = 60000 // BATCH_SIZE\n","NUM_VAL_BATCHES = 10000 // BATCH_SIZE\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","# create train, eval, and test datasets\n","train_original_data = datasets.MNIST(root=ROOT_DIR, train=True, download=True, transform=original_transform_train) # train data\n","eval_original_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=original_transform_train) # test data WITHOUT affine transforms\n","test_original_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=original_transform_test) # test data WITH affine transforms\n","\n","\n","# create generator for dataloaders and create dataloaders for each dataset\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_original_loader = DataLoader(train_original_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","eval_original_loader = DataLoader(eval_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_original_loader = DataLoader(test_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","\n","# initalize model object and load model parameters into optimizer\n","model = LinearClassifierOriginal()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","for i in range(EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_original_loader,model=model,loss_fn=loss_fn,optimizer=optimizer)\n","    eval_loop()\n","    print(\"\\n-------------------------------\\n\")\n","  \n","test_loop() "]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651790815257,"user_tz":420,"elapsed":367339,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"da606924-05b1-4b7c-f257-8de9a4b8bd2a","id":"W9MnQt8lVVgb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 2.297735  [    0/60000]\n","loss: 0.454847  [50000/60000]\n","test accuracy: 0.884000\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.355037  [    0/60000]\n","loss: 0.235952  [50000/60000]\n","test accuracy: 0.927200\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.255411  [    0/60000]\n","loss: 0.247383  [50000/60000]\n","test accuracy: 0.936300\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.205320  [    0/60000]\n","loss: 0.192373  [50000/60000]\n","test accuracy: 0.949700\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.229786  [    0/60000]\n","loss: 0.137371  [50000/60000]\n","test accuracy: 0.946300\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.166466  [    0/60000]\n","loss: 0.128476  [50000/60000]\n","test accuracy: 0.955800\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.151000  [    0/60000]\n","loss: 0.137463  [50000/60000]\n","test accuracy: 0.960500\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.140446  [    0/60000]\n","loss: 0.083567  [50000/60000]\n","test accuracy: 0.960000\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.167239  [    0/60000]\n","loss: 0.101422  [50000/60000]\n","test accuracy: 0.962600\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.111060  [    0/60000]\n","loss: 0.099166  [50000/60000]\n","test accuracy: 0.967500\n","\n","-------------------------------\n","\n","test accuracy with affine transformations: 0.979800\n"]}],"source":["# TODO: create original image dataset\n","# TODO: create generators for original dataset\n","# Env vars\n","torch.use_deterministic_algorithms(True) # to ensure reproduceability\n","ROOT_DIR = \"/mnist\"\n","RAND_SEED = 0\n","DEVICE = \"cpu\"\n","\n","# training hyperparameters\n","NUM_CLASSES = 10\n","EPOCHS = 10\n","#FOURIER_ORDER = 10\n","LEARNING_RATE = 1e-3\n","BATCH_SIZE = 500\n","NUM_TRAIN_BATCHES = 60000 // BATCH_SIZE\n","NUM_VAL_BATCHES = 10000 // BATCH_SIZE\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","# create train, eval, and test datasets\n","train_original_data = datasets.MNIST(root=ROOT_DIR, train=True, download=True, transform=original_transform_test) # train data\n","eval_original_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=original_transform_test) # test data WITHOUT affine transforms\n","test_original_data = datasets.MNIST(root=ROOT_DIR, train=False, download=True, transform=original_transform_train) # test data WITH affine transforms\n","\n","\n","# create generator for dataloaders and create dataloaders for each dataset\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_original_loader = DataLoader(train_original_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","eval_original_loader = DataLoader(eval_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_original_loader = DataLoader(test_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","\n","# initalize model object and load model parameters into optimizer\n","model = LinearClassifierOriginal()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","for i in range(EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_original_loader,model=model,loss_fn=loss_fn,optimizer=optimizer)\n","    eval_loop()\n","    print(\"\\n-------------------------------\\n\")\n","  \n","test_loop() "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Fourier Descriptors -- MNIST Linear.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}