{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16430,"status":"ok","timestamp":1664481568330,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"},"user_tz":420},"id":"IiJuHUdQvdYp","outputId":"4befbd31-81ea-4253-e330-b595960512af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wDjjZFaGNZXV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664481580101,"user_tz":420,"elapsed":11773,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}},"outputId":"effae9af-d132-4ef3-89bb-9c4085bfd611"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyefd\n","  Downloading pyefd-1.6.0-py2.py3-none-any.whl (7.7 kB)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyefd) (1.21.6)\n","Installing collected packages: pyefd\n","Successfully installed pyefd-1.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cairocffi\n","  Downloading cairocffi-1.4.0.tar.gz (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n","Building wheels for collected packages: cairocffi\n","  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cairocffi: filename=cairocffi-1.4.0-py3-none-any.whl size=88775 sha256=71d6291b5ba3427f20af9359885fc7aea541e32dfd11a0f2cf6537e25719d972\n","  Stored in directory: /root/.cache/pip/wheels/7a/2b/da/aec872f95d2c24105496ef149a9a576f52daf686f8f2127541\n","Successfully built cairocffi\n","Installing collected packages: cairocffi\n","Successfully installed cairocffi-1.4.0\n"]}],"source":["import os\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms as T\n","import random\n","import cv2\n","import numpy as np\n","!pip install pyefd\n","import pyefd\n","from google.colab.patches import cv2_imshow\n","!pip install cairocffi\n","import cairocffi as cairo\n","import struct\n","from struct import unpack"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"q9cgJ84nZ1qR","executionInfo":{"status":"ok","timestamp":1664481908710,"user_tz":420,"elapsed":256,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}}},"outputs":[],"source":["# Env vars\n","torch.use_deterministic_algorithms(False)\n","\n","# Const vars\n","LOAD_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 CNN-Fourier hybrid 28.pt'\n","RAND_SEED = 0\n","DEVICE = \"cuda\"\n","\n","FOURIER_ORDER = 1\n","IMG_SIDE = 28\n","IMG_CENTER = np.asarray(((IMG_SIDE - 1) / 2, (IMG_SIDE - 1) / 2))\n","NUM_CLASSES = 25\n","EPOCHS = 10\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 512\n","LOSS_FN = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"OesVurZASnQW","executionInfo":{"status":"ok","timestamp":1664481910445,"user_tz":420,"elapsed":223,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}}},"outputs":[],"source":["# convert raw vector image to single raster image\n","def vector_to_raster(vector_image, side=IMG_SIDE, line_diameter=16, padding=80, bg_color=(0,0,0), fg_color=(1,1,1)):\n","  \"\"\"\n","  padding and line_diameter are relative to the original 256x256 image.\n","  \"\"\"\n","  \n","  original_side = 256.\n","  \n","  surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n","  ctx = cairo.Context(surface)\n","  ctx.set_antialias(cairo.ANTIALIAS_BEST)\n","  ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n","  ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n","  ctx.set_line_width(line_diameter)\n","\n","  # scale to match the new size\n","  # add padding at the edges for the line_diameter\n","  # and add additional padding to account for antialiasing\n","  total_padding = padding * 2. + line_diameter\n","  new_scale = float(side) / float(original_side + total_padding)\n","  ctx.scale(new_scale, new_scale)\n","  ctx.translate(total_padding / 2., total_padding / 2.)\n","      \n","  bbox = np.hstack(vector_image).max(axis=1)\n","  offset = ((original_side, original_side) - bbox) / 2.\n","  offset = offset.reshape(-1,1)\n","  centered = [stroke + offset for stroke in vector_image]\n","\n","  # clear background\n","  ctx.set_source_rgb(*bg_color)\n","  ctx.paint()\n","\n","  # draw strokes, this is the most cpu-intensive part\n","  ctx.set_source_rgb(*fg_color)     \n","  for xv, yv in centered:   \n","    ctx.move_to(xv[0], yv[0])\n","    for x, y in zip(xv, yv):\n","        ctx.line_to(x, y)\n","    ctx.stroke()\n","\n","  data = surface.get_data()\n","  raster = np.copy(np.asarray(data)[::4]).reshape(side, side)\n","  return raster\n","\n","# Define transformation(s) to be applied to dataset-\n","transforms_norm = T.Compose(\n","      [\n","          T.ToTensor(), # scales integer inputs in the range [0, 255] into the range [0.0, 1.0]\n","          T.Normalize(mean=(0.138), std=(0.296)) # Quickdraw mean and stdev (35.213, 75.588), divided by 255\n","      ]\n","  )\n","\n","transforms_tensor = T.Compose(\n","      [\n","          T.ToTensor(), # scales integer inputs in the range [0, 255] into the range [0.0, 1.0] \n","      ]\n","  )\n","\n","# transform functions - take sketch image, return torch tensor of descriptors\n","def transform(vector_img, is_test):\n","  raster = vector_to_raster(vector_img)\n","\n","  # add rotations and translations at test time\n","  if is_test: \n","    raster = transforms_tensor(raster.astype(np.float32))\n","\n","    angle = random.random()*60 - 30\n","    deltaX = random.randint(-3, 3)\n","    deltaY = random.randint(-3, 3)\n","\n","    raster = T.functional.affine(raster, angle, [deltaX, deltaY], 1, 0,\n","                                 interpolation=T.InterpolationMode.BILINEAR)\n","    raster = np.squeeze(raster.numpy()).astype(np.uint8)\n","  \n","  # fourier transform of outer contour to get rotation angle\n","  raster_binary = cv2.threshold(raster, 100, 255, cv2.THRESH_BINARY)[1]\n","  contours, hierarchy = cv2.findContours(raster_binary, \n","                                         cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","  \n","  largest_size = 0\n","  largest_index = 0\n","  for k, contour in enumerate(contours):\n","      if len(contour) > largest_size:\n","        largest_size = len(contour)\n","        largest_index = k\n","\n","  contour = np.squeeze(contours[largest_index])\n","  sketch_center = pyefd.calculate_dc_coefficients(contour)\n","  coeffs, transform = pyefd.elliptic_fourier_descriptors(contour, order=FOURIER_ORDER, normalize=True, return_transformation=True)\n","  contour_angle = np.degrees(transform[1])\n","  img_offset = (IMG_CENTER - sketch_center).round()\n","\n","  # de-translate and de-rotate\n","  raster = transforms_norm(raster)\n","  raster = T.functional.affine(raster, 0, (img_offset[0], img_offset[1]), 1, 0,\n","                                 interpolation=T.InterpolationMode.BILINEAR)\n","  raster = T.functional.affine(raster, -1 * contour_angle, [0, 0], 1, 0,\n","                                 interpolation=T.InterpolationMode.BILINEAR)\n","  return raster\n","\n","# helper method to find class based on imgset index\n","def find_class(idx, num_list):\n","  class_id = 0\n","  sum = num_list[class_id]\n","  while idx >= sum:\n","    class_id += 1\n","    sum += num_list[class_id]\n","  return class_id\n","\n","# deterministic worker re-seeding\n","def seed_worker(worker_id):\n","  worker_seed = torch.initial_seed() % 2**32\n","  np.random.seed(worker_seed)\n","  random.seed(worker_seed)\n","\n","# custom dataset for quickdraw\n","class QuickdrawDataset(Dataset):\n","  def __init__(self, imgs, nums, is_test):\n","    self.imgs = imgs\n","    self.nums = nums\n","    self.len = sum(nums)\n","    self.is_test = is_test\n","\n","  def __len__(self):\n","    return self.len\n","\n","  def __getitem__(self, idx):\n","    img = self.imgs[idx]\n","    x = transform(img, self.is_test)\n","    y = find_class(idx, self.nums)\n","    return x, y\n","\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 64, 3)\n","        self.conv2 = nn.Conv2d(64, 64, 3)\n","        self.conv3 = nn.Conv2d(64, 64, 3)\n","        self.conv4 = nn.Conv2d(64, 64, 3)\n","        self.maxpool = nn.MaxPool2d(2) \n","        self.relu = nn.ReLU()\n","        self.fc1 = nn.Linear(64 * 4 * 4, 384)\n","        self.head = nn.Linear(384, NUM_CLASSES)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.conv3(x)\n","        x = self.relu(x)\n","        x = self.conv4(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        return self.head(x)\n","\n","# class CNN(nn.Module):\n","#     def __init__(self):\n","#         super(CNN, self).__init__()\n","#         self.conv1 = nn.Conv2d(1, 32, 3, padding='same')\n","#         self.conv2 = nn.Conv2d(32, 32, 3, padding='same')\n","#         self.conv3 = nn.Conv2d(32, 64, 3, padding='same')\n","#         self.conv4 = nn.Conv2d(64, 64, 3, padding='same')\n","#         self.conv5 = nn.Conv2d(64, 128, 3, padding='same')\n","#         self.conv6 = nn.Conv2d(128, 128, 3, padding='same')\n","#         self.maxpool = nn.MaxPool2d(2) \n","#         self.relu = nn.ReLU()\n","#         self.fc1 = nn.Linear(128 * 4 * 4, 512)\n","#         self.head = nn.Linear(512, NUM_CLASSES)\n","\n","#     def forward(self, x):\n","#         x = self.conv1(x)\n","#         x = self.maxpool(x)\n","#         x = self.relu(x)\n","#         x = self.conv2(x)\n","#         x = self.maxpool(x)\n","#         x = self.relu(x)\n","#         x = self.conv3(x)\n","#         x = self.maxpool(x)\n","#         x = self.relu(x)\n","#         x = self.conv4(x)\n","#         x = self.maxpool(x)\n","#         x = self.relu(x)\n","#         x = self.conv5(x)\n","#         x = self.maxpool(x)\n","#         x = self.relu(x)\n","#         x = self.conv6(x)\n","#         x = self.maxpool(x)\n","#         x = self.relu(x)\n","#         x = torch.flatten(x, 1)\n","#         x = self.fc1(x)\n","#         x = self.relu(x)\n","#         return self.head(x)\n","\n","\n","def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train() # put the model in train mode\n","    total_loss = 0\n","    total_correct = 0\n","    # for each batch in the training set compute loss and update model parameters\n","    for batch, (x, y) in enumerate(dataloader):\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      # Compute prediction and loss\n","      out = model(x)\n","      loss = loss_fn(out, y)\n","\n","      # Backpropagation to update model parameters\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # print current training metrics for user\n","      y, out, loss = y.to(\"cpu\"), out.to(\"cpu\"), loss.to(\"cpu\")\n","      loss_val = loss.item()\n","      if batch % 10 == 0:\n","          current = (batch + 1) * BATCH_SIZE\n","          print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","      pred = out.argmax(dim=1, keepdim=True)\n","      correct = pred.eq(y.view_as(pred)).sum().item()\n","      total_correct += correct\n","      total_loss += loss_val\n","      # print(f\"train loss: {loss_val:>7f}   train accuracy: {correct / BATCH_SIZE:>7f}   [batch: {batch + 1:>3d}/{(size // BATCH_SIZE) + 1:>3d}]\")      \n","    print(f\"\\nepoch avg train loss: {total_loss / ((size // BATCH_SIZE) + 1):>7f}   epoch avg train accuracy: {total_correct / size:>7f}\")\n","      \n","def eval_loop(dataloader, model):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  with torch.no_grad():\n","    total_correct = 0\n","    for x, y in dataloader:\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      out = model(x)\n","      y, out = y.to(\"cpu\"), out.to(\"cpu\")\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    accuracy = total_correct / size\n","    return accuracy\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3yQmzmk8hsDL","executionInfo":{"status":"ok","timestamp":1664481580536,"user_tz":420,"elapsed":4,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}}},"outputs":[],"source":["# define methods for unpacking Quickdraw .bin files\n","def unpack_drawing(file_handle):\n","  file_handle.read(15)\n","  n_strokes, = unpack('H', file_handle.read(2))\n","  image = []\n","  for i in range(n_strokes):\n","      n_points, = unpack('H', file_handle.read(2))\n","      fmt = str(n_points) + 'B'\n","      x = unpack(fmt, file_handle.read(n_points))\n","      y = unpack(fmt, file_handle.read(n_points))\n","      image.append((x, y))\n","\n","  return image\n","\n","\n","def unpack_drawings(filename):\n","  imageset = []\n","  with open(filename, 'rb') as f:\n","      while True:\n","          try:\n","              imageset.append(unpack_drawing(f))\n","          except struct.error:\n","              break\n","  return imageset\n","\n","train_dir = '/content/drive/My Drive/Fourier/Quickdraw Dataset Small/Train/'\n","test_dir = '/content/drive/My Drive/Fourier/Quickdraw Dataset Small/Test/'\n","train_imgs = []\n","test_imgs = []\n","train_nums = []\n","test_nums = []\n","list_of_classes = [\"arm\", \"brain\", \"circle\", \"ear\", \"elbow\", \"eye\", \n","                   \"face\", \"finger\", \"foot\", \"hand\", \"hexagon\", \"knee\", \n","                   \"leg\", \"line\", \"mouth\", \"nose\", \"octagon\", \n","                   'skull', 'square', 'squiggle', 'star', 'toe', 'tooth', \n","                   'triangle', 'zigzag']\n","# list_of_classes = [\"aircraft carrier\", \"airplane\", \"alarm clock\", \"ambulance\", \n","#                    \"angel\", \"ant\", \"anvil\", \"apple\", \"arm\", \"asparagus\", \"axe\", \n","#                    \"backpack\", \"banana\", \"bandage\", \"barn\", \"baseball bat\", \n","#                    \"baseball\", \"basket\", \"basketball\", \"bathtub\", \"beach\", \"bear\", \n","#                    \"beard\", \"bed\", \"bee\"]"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"NNCgN-LshS9t","executionInfo":{"status":"ok","timestamp":1664481602141,"user_tz":420,"elapsed":21606,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}}},"outputs":[],"source":["# load dataset\n","for item in list_of_classes:\n","  train_folder = train_dir + item + '.bin'\n","  test_folder = test_dir + item + '.bin'\n","  train_drawings = unpack_drawings(train_folder)\n","  train_imgs += train_drawings\n","  train_nums.append(len(train_drawings))\n","  test_drawings = unpack_drawings(test_folder)\n","  test_imgs += test_drawings\n","  test_nums.append(len(test_drawings))"]},{"cell_type":"code","source":["DEVICE = \"cpu\"\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","\n","def get_confusion_mat(dataloader, model):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  conf_mat = np.zeros((NUM_CLASSES, NUM_CLASSES))\n","  with torch.no_grad():\n","    total_correct = 0\n","    for x, y in dataloader:\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      out = model(x)\n","      y, out = y.to(\"cpu\"), out.to(\"cpu\")\n","      pred = out.argmax(dim=1, keepdim=True)\n","      y = y.view_as(pred)\n","      total_correct += pred.eq(y).sum().item()\n","      y, pred = y.numpy(), pred.numpy()\n","      indices = np.concatenate((y, pred), axis=1)\n","      for i in range(indices.shape[0]):\n","        conf_mat[indices[i, 0], indices[i, 1]] += 1\n","\n","    accuracy = total_correct / size\n","    print(f\"test accuracy: {accuracy:>7f}\")\n","    return conf_mat\n","\n","eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","model = CNN()\n","checkpoint = torch.load(LOAD_PATH, map_location=torch.device(DEVICE))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","\n","random.seed(RAND_SEED)\n","conf_mat = get_confusion_mat(dataloader=eval_loader,model=model)\n","conf_mat_norm = conf_mat * (255 / 100)\n","cv2_imshow(conf_mat_norm)\n","\n","diag = np.diagonal(conf_mat)\n","sums = np.asarray(test_nums)\n","accuracies = diag / sums\n","acc_sorted_idxs = np.argsort(accuracies)\n","for i in range(NUM_CLASSES):\n","  print(list_of_classes[acc_sorted_idxs[i]] + \" accuracy \" + str(accuracies[acc_sorted_idxs[i]]))\n","\n","print(\"\\n\")\n","\n","diag_mat = np.multiply(np.identity(NUM_CLASSES), conf_mat)\n","conf_mat_nodiag = conf_mat - diag_mat\n","conf_mat_sorted = np.argsort(conf_mat_nodiag, axis=None)\n","for i in range(1, 6):\n","  print(\"class \" + list_of_classes[conf_mat_sorted[-i] // NUM_CLASSES] + \" misclassified as \" + list_of_classes[conf_mat_sorted[-i] % NUM_CLASSES])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":615},"id":"bL9Hg9zGsoP0","executionInfo":{"status":"ok","timestamp":1663271553075,"user_tz":420,"elapsed":101854,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"232327d6-5bb1-41a0-f625-18a544564f9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test accuracy: 0.705082\n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=L size=25x25 at 0x7F0DD56E09D0>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABkAAAAZCAAAAADhgtq/AAABHklEQVR4nE3SsYpUURCE4Y+CouFyYRhYhIHB0MQX22cQwdgXMDERzAwFk0UwMTHZNzBcMPMVDM4d1pMc6MP5q7q6fYw5x+wxe1KMAV9bCYXKbtPd0KcECBJyFE7zoCHEtEkW7S7yNskur5lpTBeg4rFdpJ1KF/2U2B8WLWLn+BXFFyfdNWKcktjKFnlXPSdnMi4jJpBrfshh/fCw2oCfVF8tNbT6gu68udYJZ10hrb5fcvfhEpiDe5gHf62XdTZjJsH4HhHZkGSrpmZOfJ6oNY1O1wTuk6T3yc3uRdietR6Rm1QQPcbyFBq0WV1lCyP51K3OzxEEJcyfddWmrntkS0ds3hP2rA0RSZqZpt/kP1rEDZ/fq9iVXY+luQq//gHoehhbnDpwIwAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["octagon accuracy 0.41\n","knee accuracy 0.48\n","elbow accuracy 0.49\n","foot accuracy 0.5\n","toe accuracy 0.5454545454545454\n","leg accuracy 0.59\n","arm accuracy 0.61\n","squiggle accuracy 0.63\n","nose accuracy 0.64\n","finger accuracy 0.67\n","brain accuracy 0.7\n","tooth accuracy 0.71\n","ear accuracy 0.73\n","face accuracy 0.73\n","mouth accuracy 0.74\n","hand accuracy 0.75\n","hexagon accuracy 0.77\n","zigzag accuracy 0.79\n","skull accuracy 0.81\n","eye accuracy 0.81\n","triangle accuracy 0.87\n","circle accuracy 0.9\n","square accuracy 0.9\n","star accuracy 0.91\n","line accuracy 0.94\n","\n","\n","class octagon misclassified as hexagon\n","class elbow misclassified as knee\n","class hexagon misclassified as octagon\n","class leg misclassified as foot\n","class knee misclassified as leg\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 CNN-Fourier hybrid 28.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GihtNBQJ1GgP","executionInfo":{"status":"ok","timestamp":1664482372658,"user_tz":420,"elapsed":446666,"user":{"displayName":"Matt Watson","userId":"10419224003756061351"}},"outputId":"b47c75ad-1427-4f41-95cc-c22149a1c813"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.218214  [  512/25000]\n","loss: 2.546573  [ 5632/25000]\n","loss: 2.239836  [10752/25000]\n","loss: 2.246207  [15872/25000]\n","loss: 1.895253  [20992/25000]\n","\n","epoch avg train loss: 2.329290   epoch avg train accuracy: 0.306920\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.870393  [  512/25000]\n","loss: 1.814686  [ 5632/25000]\n","loss: 1.774582  [10752/25000]\n","loss: 1.619098  [15872/25000]\n","loss: 1.667599  [20992/25000]\n","\n","epoch avg train loss: 1.670068   epoch avg train accuracy: 0.512240\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 1.390854  [  512/25000]\n","loss: 1.460320  [ 5632/25000]\n","loss: 1.398507  [10752/25000]\n","loss: 1.287602  [15872/25000]\n","loss: 1.383924  [20992/25000]\n","\n","epoch avg train loss: 1.350327   epoch avg train accuracy: 0.598800\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 1.212597  [  512/25000]\n","loss: 1.170589  [ 5632/25000]\n","loss: 1.323010  [10752/25000]\n","loss: 1.285719  [15872/25000]\n","loss: 1.330026  [20992/25000]\n","\n","epoch avg train loss: 1.205600   epoch avg train accuracy: 0.635720\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 1.127364  [  512/25000]\n","loss: 1.014311  [ 5632/25000]\n","loss: 1.167368  [10752/25000]\n","loss: 1.137188  [15872/25000]\n","loss: 1.082304  [20992/25000]\n","\n","epoch avg train loss: 1.097855   epoch avg train accuracy: 0.665280\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.930148  [  512/25000]\n","loss: 0.960339  [ 5632/25000]\n","loss: 1.068829  [10752/25000]\n","loss: 0.967259  [15872/25000]\n","loss: 1.059823  [20992/25000]\n","\n","epoch avg train loss: 1.010421   epoch avg train accuracy: 0.691080\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 1.053839  [  512/25000]\n","loss: 0.931276  [ 5632/25000]\n","loss: 0.882178  [10752/25000]\n","loss: 0.832046  [15872/25000]\n","loss: 1.103724  [20992/25000]\n","\n","epoch avg train loss: 0.932340   epoch avg train accuracy: 0.713880\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.877776  [  512/25000]\n","loss: 0.811590  [ 5632/25000]\n","loss: 0.756450  [10752/25000]\n","loss: 0.884059  [15872/25000]\n","loss: 0.825054  [20992/25000]\n","\n","epoch avg train loss: 0.855217   epoch avg train accuracy: 0.734640\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.823025  [  512/25000]\n","loss: 0.880648  [ 5632/25000]\n","loss: 0.795591  [10752/25000]\n","loss: 0.792167  [15872/25000]\n","loss: 0.838035  [20992/25000]\n","\n","epoch avg train loss: 0.775454   epoch avg train accuracy: 0.755640\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.687319  [  512/25000]\n","loss: 0.706747  [ 5632/25000]\n","loss: 0.679911  [10752/25000]\n","loss: 0.634310  [15872/25000]\n","loss: 0.787079  [20992/25000]\n","\n","epoch avg train loss: 0.716480   epoch avg train accuracy: 0.773720\n","\n","-------------------------------\n","\n","0.6625316793384022\n","0.004578098519869419\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25-2 CNN-Fourier hybrid 256.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PExshQ3iNZG","executionInfo":{"status":"ok","timestamp":1664479513974,"user_tz":420,"elapsed":1914388,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"7b7c60e5-fc0c-46a0-ee46-a9a5a6350c26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.221137  [  128/24999]\n","loss: 2.436512  [ 6528/24999]\n","loss: 2.238842  [12928/24999]\n","loss: 1.698128  [19328/24999]\n","\n","epoch avg train loss: 2.221313   epoch avg train accuracy: 0.335973\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.781789  [  128/24999]\n","loss: 1.428232  [ 6528/24999]\n","loss: 1.408190  [12928/24999]\n","loss: 1.268780  [19328/24999]\n","\n","epoch avg train loss: 1.322341   epoch avg train accuracy: 0.609424\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.820000  [  128/24999]\n","loss: 1.172077  [ 6528/24999]\n","loss: 1.076967  [12928/24999]\n","loss: 0.891448  [19328/24999]\n","\n","epoch avg train loss: 1.016731   epoch avg train accuracy: 0.697268\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.921771  [  128/24999]\n","loss: 0.946426  [ 6528/24999]\n","loss: 0.905878  [12928/24999]\n","loss: 0.920459  [19328/24999]\n","\n","epoch avg train loss: 0.828274   epoch avg train accuracy: 0.755110\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.688732  [  128/24999]\n","loss: 0.529428  [ 6528/24999]\n","loss: 0.660384  [12928/24999]\n","loss: 0.614486  [19328/24999]\n","\n","epoch avg train loss: 0.687289   epoch avg train accuracy: 0.792672\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.454535  [  128/24999]\n","loss: 0.509400  [ 6528/24999]\n","loss: 0.578637  [12928/24999]\n","loss: 0.529476  [19328/24999]\n","\n","epoch avg train loss: 0.555998   epoch avg train accuracy: 0.830553\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.420462  [  128/24999]\n","loss: 0.476964  [ 6528/24999]\n","loss: 0.463819  [12928/24999]\n","loss: 0.567872  [19328/24999]\n","\n","epoch avg train loss: 0.448240   epoch avg train accuracy: 0.860274\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.294253  [  128/24999]\n","loss: 0.377072  [ 6528/24999]\n","loss: 0.395711  [12928/24999]\n","loss: 0.270220  [19328/24999]\n","\n","epoch avg train loss: 0.353530   epoch avg train accuracy: 0.885035\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.277024  [  128/24999]\n","loss: 0.206417  [ 6528/24999]\n","loss: 0.219918  [12928/24999]\n","loss: 0.194297  [19328/24999]\n","\n","epoch avg train loss: 0.281116   epoch avg train accuracy: 0.908796\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.177763  [  128/24999]\n","loss: 0.120881  [ 6528/24999]\n","loss: 0.148779  [12928/24999]\n","loss: 0.313861  [19328/24999]\n","\n","epoch avg train loss: 0.223847   epoch avg train accuracy: 0.925237\n","\n","-------------------------------\n","\n","0.7067600000000002\n","0.003478467095335719\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 CNN-Fourier hybrid 256.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sh89d9oC8wO","executionInfo":{"status":"ok","timestamp":1663262553494,"user_tz":420,"elapsed":1872267,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"d2037f47-f186-464e-b1a3-0e00913d27dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.215290  [  128/25000]\n","loss: 2.357484  [ 6528/25000]\n","loss: 1.836048  [12928/25000]\n","loss: 1.262836  [19328/25000]\n","\n","epoch avg train loss: 1.853188   epoch avg train accuracy: 0.443560\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.502856  [  128/25000]\n","loss: 1.198589  [ 6528/25000]\n","loss: 1.030130  [12928/25000]\n","loss: 1.029954  [19328/25000]\n","\n","epoch avg train loss: 1.132605   epoch avg train accuracy: 0.658080\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.989774  [  128/25000]\n","loss: 1.043535  [ 6528/25000]\n","loss: 0.849469  [12928/25000]\n","loss: 0.832838  [19328/25000]\n","\n","epoch avg train loss: 0.929748   epoch avg train accuracy: 0.716480\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.723786  [  128/25000]\n","loss: 0.751628  [ 6528/25000]\n","loss: 0.817513  [12928/25000]\n","loss: 0.852584  [19328/25000]\n","\n","epoch avg train loss: 0.787410   epoch avg train accuracy: 0.757880\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.680723  [  128/25000]\n","loss: 0.626822  [ 6528/25000]\n","loss: 0.648689  [12928/25000]\n","loss: 0.785088  [19328/25000]\n","\n","epoch avg train loss: 0.659037   epoch avg train accuracy: 0.794800\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.465208  [  128/25000]\n","loss: 0.480737  [ 6528/25000]\n","loss: 0.562359  [12928/25000]\n","loss: 0.730643  [19328/25000]\n","\n","epoch avg train loss: 0.559827   epoch avg train accuracy: 0.819160\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.595725  [  128/25000]\n","loss: 0.367324  [ 6528/25000]\n","loss: 0.431849  [12928/25000]\n","loss: 0.366562  [19328/25000]\n","\n","epoch avg train loss: 0.455081   epoch avg train accuracy: 0.849040\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.336125  [  128/25000]\n","loss: 0.245595  [ 6528/25000]\n","loss: 0.506205  [12928/25000]\n","loss: 0.479073  [19328/25000]\n","\n","epoch avg train loss: 0.372224   epoch avg train accuracy: 0.876520\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.242389  [  128/25000]\n","loss: 0.283812  [ 6528/25000]\n","loss: 0.296800  [12928/25000]\n","loss: 0.309184  [19328/25000]\n","\n","epoch avg train loss: 0.293967   epoch avg train accuracy: 0.903080\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.167380  [  128/25000]\n","loss: 0.141458  [ 6528/25000]\n","loss: 0.193661  [12928/25000]\n","loss: 0.360896  [19328/25000]\n","\n","epoch avg train loss: 0.238518   epoch avg train accuracy: 0.920440\n","\n","-------------------------------\n","\n","0.6877684407096173\n","0.0038492171970428693\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J1t1TKOBHG-R","outputId":"3733d510-9b38-4faf-9f24-b8804fcf23fa","executionInfo":{"status":"ok","timestamp":1663193379364,"user_tz":420,"elapsed":505758,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.333240  [  128/28000]\n","loss: 2.536796  [ 6528/28000]\n","loss: 2.020702  [12928/28000]\n","loss: 1.729918  [19328/28000]\n","loss: 1.318714  [25728/28000]\n","\n","epoch avg train loss: 2.003457   epoch avg train accuracy: 0.410679\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.455695  [  128/28000]\n","loss: 1.322622  [ 6528/28000]\n","loss: 1.207758  [12928/28000]\n","loss: 1.417399  [19328/28000]\n","loss: 1.218234  [25728/28000]\n","\n","epoch avg train loss: 1.253825   epoch avg train accuracy: 0.630429\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.910056  [  128/28000]\n","loss: 1.015385  [ 6528/28000]\n","loss: 1.085217  [12928/28000]\n","loss: 1.322178  [19328/28000]\n","loss: 0.855367  [25728/28000]\n","\n","epoch avg train loss: 1.039027   epoch avg train accuracy: 0.689143\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.885309  [  128/28000]\n","loss: 0.778443  [ 6528/28000]\n","loss: 0.784753  [12928/28000]\n","loss: 0.844654  [19328/28000]\n","loss: 0.852926  [25728/28000]\n","\n","epoch avg train loss: 0.880865   epoch avg train accuracy: 0.730000\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.807796  [  128/28000]\n","loss: 0.774759  [ 6528/28000]\n","loss: 0.825705  [12928/28000]\n","loss: 0.659585  [19328/28000]\n","loss: 0.845623  [25728/28000]\n","\n","epoch avg train loss: 0.761585   epoch avg train accuracy: 0.764607\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.776964  [  128/28000]\n","loss: 0.611377  [ 6528/28000]\n","loss: 0.612794  [12928/28000]\n","loss: 0.655767  [19328/28000]\n","loss: 0.768663  [25728/28000]\n","\n","epoch avg train loss: 0.655721   epoch avg train accuracy: 0.794143\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.670662  [  128/28000]\n","loss: 0.576748  [ 6528/28000]\n","loss: 0.514861  [12928/28000]\n","loss: 0.644724  [19328/28000]\n","loss: 0.469579  [25728/28000]\n","\n","epoch avg train loss: 0.558567   epoch avg train accuracy: 0.822000\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.491301  [  128/28000]\n","loss: 0.556369  [ 6528/28000]\n","loss: 0.340408  [12928/28000]\n","loss: 0.325175  [19328/28000]\n","loss: 0.278008  [25728/28000]\n","\n","epoch avg train loss: 0.458248   epoch avg train accuracy: 0.849000\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.304226  [  128/28000]\n","loss: 0.206060  [ 6528/28000]\n","loss: 0.420437  [12928/28000]\n","loss: 0.374873  [19328/28000]\n","loss: 0.434523  [25728/28000]\n","\n","epoch avg train loss: 0.372186   epoch avg train accuracy: 0.877179\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.367675  [  128/28000]\n","loss: 0.316090  [ 6528/28000]\n","loss: 0.333209  [12928/28000]\n","loss: 0.337234  [19328/28000]\n","loss: 0.226495  [25728/28000]\n","\n","epoch avg train loss: 0.318064   epoch avg train accuracy: 0.892464\n","\n","-------------------------------\n","\n","0.6731094438489936\n","0.0036961907236321965\n"]}],"source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/CNN subset256.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1VOb_ZBx7oH74XGgXPClS2KbAdbjN_9Z2","timestamp":1663187824815},{"file_id":"1YbnaTcA2O78WEFXdGIOmPkDRM18AVJ2X","timestamp":1663109377147},{"file_id":"1-Zu9875EPh8lpZKZBL92PY0SI_EZj2R8","timestamp":1660851002402},{"file_id":"1HmEE3jGUpn2AzNnSdBfhtm74OSHAmt0o","timestamp":1650055586271},{"file_id":"1owTDTec1_uglqFzHWQQKQbfPBG9Ge_Ep","timestamp":1649121474527}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}