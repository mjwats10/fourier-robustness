{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12028,"status":"ok","timestamp":1651790876610,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"},"user_tz":420},"id":"wDjjZFaGNZXV","outputId":"c3245fb8-b160-43bc-a44c-a1c5a4f21579"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyefd\n","  Downloading pyefd-1.6.0-py2.py3-none-any.whl (7.7 kB)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyefd) (1.21.6)\n","Installing collected packages: pyefd\n","Successfully installed pyefd-1.6.0\n"]}],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms as T\n","import random\n","import cv2\n","import numpy as np\n","!pip install pyefd\n","import pyefd\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"ZSpVSjCyUPb6"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9cgJ84nZ1qR"},"outputs":[],"source":["# Env vars\n","torch.use_deterministic_algorithms(True)\n","\n","# Const vars\n","ROOT_DIR = \"./\"\n","RAND_SEED = 0\n","DEVICE = \"cpu\"\n","\n","NUM_CLASSES = 3\n","EPOCHS = 10\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 500\n","NUM_TRAIN_BATCHES = 60000 // BATCH_SIZE\n","NUM_VAL_BATCHES = 10000 // BATCH_SIZE\n","LOSS_FN = nn.CrossEntropyLoss()\n","TRAIN_SPLIT = 0.8\n","\n","\n","# deterministic worker re-seeding\n","def seed_worker(worker_id):\n","    worker_seed = torch.initial_seed() % 2**32\n","    np.random.seed(worker_seed)\n","    random.seed(worker_seed)\n","\n","    # custom dataset for quickdraw classes circle, square, triangle\n","class QuickdrawDataset(Dataset):\n","  def __init__(self, imgs, num_circle, num_square, num_triangle, transform):\n","    self.imgs = imgs\n","    self.num_circle = num_circle\n","    self.num_square = num_square\n","    self.num_triangle = num_triangle\n","    self.len = num_circle + num_square + num_triangle\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return self.len\n","\n","  def __getitem__(self, idx):\n","    img = self.imgs[idx, :, :]\n","    x = self.transform(img)\n","    if idx < self.num_circle:\n","      y = 0\n","    elif idx < self.num_circle + self.num_square:\n","      y = 1\n","    else:\n","      y = 2\n","    return x, y"]},{"cell_type":"markdown","metadata":{"id":"Zj7ducsDUaBe"},"source":["Section 2: Original images through linear classifier (to compare)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HIZ6vG3P9Gr0"},"outputs":[],"source":["from torch.functional import Tensor\n","# mlp taking quickdraw images\n","class LinearClassifierOriginal(nn.Module):\n","    def __init__(self):\n","        super(LinearClassifierOriginal, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.mlp = nn.Sequential(\n","        nn.Linear(28*28, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, NUM_CLASSES))\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        out = self.mlp(x)\n","        return out\n","\n","# Define transformation(s) to be applied to dataset-\n","transforms_norm = T.Compose(\n","      [\n","          T.ToTensor(), # scales integer inputs in the range [0, 255] into the range [0.0, 1.0]\n","          T.Normalize(mean=(0.138), std=(0.296)) # Quickdraw mean and stdev (35.213, 75.588), divided by 255\n","          \n","      ]\n","  )\n","\n","# transform functions - take PIL image, return img as 1x28x28 torch tensor\n","def original_transform_train(img):\n","  # retrun normalized image\n","  return transforms_norm(img)\n","\n","# add rotations and translations at test time\n","# return torch tensor\n","def original_transform_test(img):\n","    img = transforms_norm(img)\n","    angle=((random.random())*60)-30\n","    \n","    transY = random.randint(-3, 3)\n","    transX = random.randint(-3, 3)\n","    new_img = T.functional.affine(img,angle,[transX,transY],1,0) \n","    return new_img\n","\n","\n","def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train() # put the model in train mode\n","    total_loss = 0\n","    total_correct = 0\n","    # for each batch in the training set compute loss and update model parameters\n","    for batch, (X, y) in enumerate(dataloader):\n","    # Compute prediction and loss\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        # Backpropagation to update model parameters\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print current training metrics for user\n","        loss_val = loss.item()\n","        if batch % 100 == 0:\n","            current = batch * len(X)\n","            print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","        pred = pred.argmax(dim=1, keepdim=True)\n","        correct = pred.eq(y.view_as(pred)).sum().item()\n","        total_correct += correct\n","        total_loss += loss_val\n","        # print(f\"train loss: {loss_val:>7f}   train accuracy: {correct / BATCH_SIZE:>7f}   [batch: {batch + 1:>3d}/{NUM_TRAIN_BATCHES:>3d}]\")      \n","    print(f\"\\nepoch avg train loss: {total_loss / (size / BATCH_SIZE):>7f}   epoch avg train accuracy: {total_correct / size:>7f}\")\n","\n","def eval_loop(dataloader, model):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  with torch.no_grad():\n","    total_correct = 0\n","    for X, y in dataloader:\n","      X, y = X.to(DEVICE), y.to(DEVICE)\n","\n","      out = model(X)\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    accuracy = total_correct / size\n","    print(f\"test accuracy: {accuracy:>7f}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14355,"status":"ok","timestamp":1651790891212,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"},"user_tz":420},"id":"53mJvDxmC6BW","outputId":"52a215d2-ed66-4d41-be80-f3c4e9672aaa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Copying gs://quickdraw_dataset/full/numpy_bitmap/circle.npy...\n","\\ [1/1 files][ 91.9 MiB/ 91.9 MiB] 100% Done                                    \n","Operation completed over 1 objects/91.9 MiB.                                     \n","Copying gs://quickdraw_dataset/full/numpy_bitmap/square.npy...\n","- [1/1 files][ 93.6 MiB/ 93.6 MiB] 100% Done                                    \n","Operation completed over 1 objects/93.6 MiB.                                     \n","Copying gs://quickdraw_dataset/full/numpy_bitmap/triangle.npy...\n","\\ [1/1 files][ 92.1 MiB/ 92.1 MiB] 100% Done                                    \n","Operation completed over 1 objects/92.1 MiB.                                     \n"]}],"source":["# download dataset and create train/test split\n","!gsutil -m cp gs://quickdraw_dataset/full/numpy_bitmap/circle.npy /circle.npy\n","!gsutil -m cp gs://quickdraw_dataset/full/numpy_bitmap/square.npy /square.npy\n","!gsutil -m cp gs://quickdraw_dataset/full/numpy_bitmap/triangle.npy /triangle.npy\n","\n","circle_imgs = np.load(\"/circle.npy\")\n","circle_len = circle_imgs.shape[0]\n","circle_train_num = int(circle_len * TRAIN_SPLIT)\n","circle_test_num = circle_len - circle_train_num\n","imgs_temp=[]\n","\n","  #vector of means= np.mean(circle_imgs, axis = 1)\n","  #vector of std= np.std(circle_imgs, axis = 1); take mean of the stds\n","\n","#calculate quickdraw mean and std\n","# quickdraw_mean = np.mean(np.mean(circle_imgs, axis = 1))\n","# quickdraw_std = np.mean(np.std(circle_imgs, axis = 1))\n","\n","for i in range(circle_len):\n","  #2nd dimension is the unrolled image\n","  #mean of each, circle[a][ith], is the unrolled image \n","  #returns a vector of means\n","  #take the mean of the vector\n","    imgs_temp.append(circle_imgs[i][:].reshape([28,28,1]))\n","imgs_temp=np.array(imgs_temp)\n","imgs_temp=imgs_temp.reshape(circle_len,28,28)\n","circle_train_imgs = imgs_temp[:circle_train_num, :, :]\n","circle_test_imgs = imgs_temp[circle_train_num:, :, :]\n","\n","\n","square_imgs = np.load(\"/square.npy\")\n","square_len = square_imgs.shape[0]\n","square_train_num = int(square_len * TRAIN_SPLIT)\n","square_test_num = square_len - square_train_num\n","imgs_temp=[]\n","for i in range(square_len):\n","    imgs_temp.append(square_imgs[i][:].reshape([28,28,1]))\n","imgs_temp=np.array(imgs_temp)\n","imgs_temp=imgs_temp.reshape(square_len,28,28)\n","square_train_imgs = imgs_temp[:square_train_num, :, :]\n","square_test_imgs = imgs_temp[square_train_num:, :, :]\n","\n","triangle_imgs = np.load(\"/triangle.npy\")\n","triangle_len = triangle_imgs.shape[0]\n","triangle_train_num = int(triangle_len * TRAIN_SPLIT)\n","triangle_test_num = triangle_len - triangle_train_num\n","imgs_temp=[]\n","for i in range(triangle_len):\n","    imgs_temp.append(triangle_imgs[i][:].reshape([28,28,1]))\n","imgs_temp=np.array(imgs_temp)\n","imgs_temp=imgs_temp.reshape(triangle_len,28,28)\n","triangle_train_imgs = imgs_temp[:triangle_train_num, :, :]\n","triangle_test_imgs = imgs_temp[triangle_train_num:, :, :]\n","\n","train_imgs = np.concatenate((circle_train_imgs, square_train_imgs, triangle_train_imgs), axis=0)\n","test_imgs = np.concatenate((circle_test_imgs, square_test_imgs, triangle_test_imgs), axis=0)\n","\n","# weed out bad imgs train indexes: [34843, 140511, 206125]\n","circle_train_num -= 1\n","square_train_num -= 1\n","triangle_train_num -= 1\n","train_imgs = np.delete(train_imgs, [34843, 140511, 206125], axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651791484610,"user_tz":420,"elapsed":593409,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"d7b74a3d-0872-4730-9aff-8c26a253fad3","id":"DmFyMPXJufUX"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 1.096165  [    0/296949]\n","loss: 0.057595  [50000/296949]\n","loss: 0.052520  [100000/296949]\n","loss: 0.054838  [150000/296949]\n","loss: 0.068327  [200000/296949]\n","loss: 0.083692  [250000/296949]\n","\n","epoch avg train loss: 0.084184   epoch avg train accuracy: 0.968207\n","test accuracy: 0.974892\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.054826  [    0/296949]\n","loss: 0.041243  [50000/296949]\n","loss: 0.071642  [100000/296949]\n","loss: 0.104768  [150000/296949]\n","loss: 0.048272  [200000/296949]\n","loss: 0.085840  [250000/296949]\n","\n","epoch avg train loss: 0.057400   epoch avg train accuracy: 0.978070\n","test accuracy: 0.976737\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.033763  [    0/296949]\n","loss: 0.072470  [50000/296949]\n","loss: 0.034303  [100000/296949]\n","loss: 0.053285  [150000/296949]\n","loss: 0.062095  [200000/296949]\n","loss: 0.039147  [250000/296949]\n","\n","epoch avg train loss: 0.049268   epoch avg train accuracy: 0.981182\n","test accuracy: 0.977155\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.044338  [    0/296949]\n","loss: 0.060070  [50000/296949]\n","loss: 0.031496  [100000/296949]\n","loss: 0.033816  [150000/296949]\n","loss: 0.036045  [200000/296949]\n","loss: 0.033639  [250000/296949]\n","\n","epoch avg train loss: 0.043083   epoch avg train accuracy: 0.983539\n","test accuracy: 0.976805\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.035912  [    0/296949]\n","loss: 0.027367  [50000/296949]\n","loss: 0.032727  [100000/296949]\n","loss: 0.039834  [150000/296949]\n","loss: 0.040291  [200000/296949]\n","loss: 0.051338  [250000/296949]\n","\n","epoch avg train loss: 0.037564   epoch avg train accuracy: 0.985732\n","test accuracy: 0.977761\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.012166  [    0/296949]\n","loss: 0.013261  [50000/296949]\n","loss: 0.021091  [100000/296949]\n","loss: 0.038845  [150000/296949]\n","loss: 0.041357  [200000/296949]\n","loss: 0.018917  [250000/296949]\n","\n","epoch avg train loss: 0.032472   epoch avg train accuracy: 0.987695\n","test accuracy: 0.977249\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.024631  [    0/296949]\n","loss: 0.031585  [50000/296949]\n","loss: 0.017998  [100000/296949]\n","loss: 0.038935  [150000/296949]\n","loss: 0.025667  [200000/296949]\n","loss: 0.020554  [250000/296949]\n","\n","epoch avg train loss: 0.028640   epoch avg train accuracy: 0.989136\n","test accuracy: 0.977330\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.017116  [    0/296949]\n","loss: 0.033779  [50000/296949]\n","loss: 0.028789  [100000/296949]\n","loss: 0.044966  [150000/296949]\n","loss: 0.043016  [200000/296949]\n","loss: 0.018760  [250000/296949]\n","\n","epoch avg train loss: 0.025335   epoch avg train accuracy: 0.990476\n","test accuracy: 0.976926\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.006387  [    0/296949]\n","loss: 0.032551  [50000/296949]\n","loss: 0.006229  [100000/296949]\n","loss: 0.030612  [150000/296949]\n","loss: 0.015492  [200000/296949]\n","loss: 0.012498  [250000/296949]\n","\n","epoch avg train loss: 0.021909   epoch avg train accuracy: 0.991638\n","test accuracy: 0.977572\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.007983  [    0/296949]\n","loss: 0.007341  [50000/296949]\n","loss: 0.016162  [100000/296949]\n","loss: 0.017068  [150000/296949]\n","loss: 0.024594  [200000/296949]\n","loss: 0.020321  [250000/296949]\n","\n","epoch avg train loss: 0.019807   epoch avg train accuracy: 0.992531\n","test accuracy: 0.977411\n","\n","-------------------------------\n","\n","test accuracy: 0.667951\n"]}],"source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_original_data = QuickdrawDataset(train_imgs, circle_train_num, square_train_num, triangle_train_num, transform=original_transform_train)\n","eval_original_data = QuickdrawDataset(test_imgs, circle_test_num, square_test_num, triangle_test_num, transform=original_transform_train)\n","test_original_data = QuickdrawDataset(test_imgs, circle_test_num, square_test_num, triangle_test_num, transform=original_transform_test)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_original_loader = DataLoader(train_original_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","eval_original_loader = DataLoader(eval_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_original_loader = DataLoader(test_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = LinearClassifierOriginal()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","for i in range(EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_original_loader,model=model,loss_fn=LOSS_FN,optimizer=optimizer)\n","    eval_loop(dataloader=eval_original_loader,model=model)\n","    print(\"\\n-------------------------------\\n\")\n","eval_loop(dataloader=test_original_loader,model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651792755649,"user_tz":420,"elapsed":1271053,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"578f736a-5bf7-43f2-d56a-1a5951425aad","id":"yLRjPloBX3my"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 1.094395  [    0/296949]\n","loss: 0.178236  [50000/296949]\n","loss: 0.175739  [100000/296949]\n","loss: 0.137356  [150000/296949]\n","loss: 0.140548  [200000/296949]\n","loss: 0.132038  [250000/296949]\n","\n","epoch avg train loss: 0.180883   epoch avg train accuracy: 0.927715\n","test accuracy: 0.954188\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 0.113573  [    0/296949]\n","loss: 0.083994  [50000/296949]\n","loss: 0.093136  [100000/296949]\n","loss: 0.144082  [150000/296949]\n","loss: 0.102903  [200000/296949]\n","loss: 0.115459  [250000/296949]\n","\n","epoch avg train loss: 0.105040   epoch avg train accuracy: 0.957936\n","test accuracy: 0.961516\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.096904  [    0/296949]\n","loss: 0.101834  [50000/296949]\n","loss: 0.073112  [100000/296949]\n","loss: 0.077982  [150000/296949]\n","loss: 0.102032  [200000/296949]\n","loss: 0.082610  [250000/296949]\n","\n","epoch avg train loss: 0.088717   epoch avg train accuracy: 0.964465\n","test accuracy: 0.965651\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.082777  [    0/296949]\n","loss: 0.108083  [50000/296949]\n","loss: 0.058535  [100000/296949]\n","loss: 0.077463  [150000/296949]\n","loss: 0.058264  [200000/296949]\n","loss: 0.077912  [250000/296949]\n","\n","epoch avg train loss: 0.080509   epoch avg train accuracy: 0.967984\n","test accuracy: 0.969356\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.077557  [    0/296949]\n","loss: 0.056686  [50000/296949]\n","loss: 0.062057  [100000/296949]\n","loss: 0.087842  [150000/296949]\n","loss: 0.087529  [200000/296949]\n","loss: 0.085164  [250000/296949]\n","\n","epoch avg train loss: 0.076138   epoch avg train accuracy: 0.969591\n","test accuracy: 0.971174\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.056492  [    0/296949]\n","loss: 0.045875  [50000/296949]\n","loss: 0.051096  [100000/296949]\n","loss: 0.066782  [150000/296949]\n","loss: 0.091056  [200000/296949]\n","loss: 0.076804  [250000/296949]\n","\n","epoch avg train loss: 0.073274   epoch avg train accuracy: 0.971008\n","test accuracy: 0.971902\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.094676  [    0/296949]\n","loss: 0.091309  [50000/296949]\n","loss: 0.066911  [100000/296949]\n","loss: 0.074138  [150000/296949]\n","loss: 0.084561  [200000/296949]\n","loss: 0.058244  [250000/296949]\n","\n","epoch avg train loss: 0.071432   epoch avg train accuracy: 0.971702\n","test accuracy: 0.972036\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.069622  [    0/296949]\n","loss: 0.053391  [50000/296949]\n","loss: 0.084549  [100000/296949]\n","loss: 0.089600  [150000/296949]\n","loss: 0.078691  [200000/296949]\n","loss: 0.077589  [250000/296949]\n","\n","epoch avg train loss: 0.069722   epoch avg train accuracy: 0.972814\n","test accuracy: 0.973006\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.048455  [    0/296949]\n","loss: 0.089653  [50000/296949]\n","loss: 0.031779  [100000/296949]\n","loss: 0.076183  [150000/296949]\n","loss: 0.077700  [200000/296949]\n","loss: 0.064808  [250000/296949]\n","\n","epoch avg train loss: 0.068288   epoch avg train accuracy: 0.973278\n","test accuracy: 0.973720\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.063984  [    0/296949]\n","loss: 0.052995  [50000/296949]\n","loss: 0.057474  [100000/296949]\n","loss: 0.063917  [150000/296949]\n","loss: 0.072780  [200000/296949]\n","loss: 0.049959  [250000/296949]\n","\n","epoch avg train loss: 0.067506   epoch avg train accuracy: 0.973591\n","test accuracy: 0.973639\n","\n","-------------------------------\n","\n","test accuracy: 0.977397\n"]}],"source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_original_data = QuickdrawDataset(train_imgs, circle_train_num, square_train_num, triangle_train_num, transform=original_transform_test)\n","eval_original_data = QuickdrawDataset(test_imgs, circle_test_num, square_test_num, triangle_test_num, transform=original_transform_test)\n","test_original_data = QuickdrawDataset(test_imgs, circle_test_num, square_test_num, triangle_test_num, transform=original_transform_train)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_original_loader = DataLoader(train_original_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","eval_original_loader = DataLoader(eval_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_original_loader = DataLoader(test_original_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = LinearClassifierOriginal()\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","for i in range(EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_original_loader,model=model,loss_fn=LOSS_FN,optimizer=optimizer)\n","    eval_loop(dataloader=eval_original_loader,model=model)\n","    print(\"\\n-------------------------------\\n\")\n","eval_loop(dataloader=test_original_loader,model=model)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Fourier Descriptors Original-- Quickdraw.ipynb","provenance":[{"file_id":"1G3XOyAf8768s3zr1brzmoIGgguwNd2Qc","timestamp":1660258191454},{"file_id":"1HmEE3jGUpn2AzNnSdBfhtm74OSHAmt0o","timestamp":1650594565511},{"file_id":"1owTDTec1_uglqFzHWQQKQbfPBG9Ge_Ep","timestamp":1649121474527}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}