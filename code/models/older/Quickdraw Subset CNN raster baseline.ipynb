{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24174,"status":"ok","timestamp":1664480114955,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"},"user_tz":420},"id":"IiJuHUdQvdYp","outputId":"656848d9-c29f-4de6-e705-e3642f2b0d9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8705,"status":"ok","timestamp":1664480123658,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"},"user_tz":420},"id":"wDjjZFaGNZXV","outputId":"a5d8d2a1-4167-4277-f03b-4f0460b0e17b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cairocffi\n","  Downloading cairocffi-1.4.0.tar.gz (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from cairocffi) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1.0->cairocffi) (2.21)\n","Building wheels for collected packages: cairocffi\n","  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cairocffi: filename=cairocffi-1.4.0-py3-none-any.whl size=88775 sha256=8249f1c20e587e09e2b7ea6d5c24a84054231c7686e84c32155f245b43fb2a85\n","  Stored in directory: /root/.cache/pip/wheels/7a/2b/da/aec872f95d2c24105496ef149a9a576f52daf686f8f2127541\n","Successfully built cairocffi\n","Installing collected packages: cairocffi\n","Successfully installed cairocffi-1.4.0\n"]}],"source":["import os\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms as T\n","import random\n","import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","!pip install cairocffi\n","import cairocffi as cairo\n","import struct\n","from struct import unpack"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q9cgJ84nZ1qR"},"outputs":[],"source":["# Env vars\n","torch.use_deterministic_algorithms(False)\n","\n","# Const vars\n","LOAD_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 CNN baseline 256 no pool.pt'\n","RAND_SEED = 0\n","DEVICE = \"cuda\"\n","\n","IMG_SIDE = 256\n","NUM_CLASSES = 25\n","EPOCHS = 10\n","LEARNING_RATE = 0.001\n","BATCH_SIZE = 128\n","LOSS_FN = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OesVurZASnQW"},"outputs":[],"source":["# convert raw vector image to single raster image\n","def vector_to_raster(vector_image, side=IMG_SIDE, line_diameter=16, padding=80, bg_color=(0,0,0), fg_color=(1,1,1)):\n","  \"\"\"\n","  padding and line_diameter are relative to the original 256x256 image.\n","  \"\"\"\n","  \n","  original_side = 256.\n","  \n","  surface = cairo.ImageSurface(cairo.FORMAT_ARGB32, side, side)\n","  ctx = cairo.Context(surface)\n","  ctx.set_antialias(cairo.ANTIALIAS_BEST)\n","  ctx.set_line_cap(cairo.LINE_CAP_ROUND)\n","  ctx.set_line_join(cairo.LINE_JOIN_ROUND)\n","  ctx.set_line_width(line_diameter)\n","\n","  # scale to match the new size\n","  # add padding at the edges for the line_diameter\n","  # and add additional padding to account for antialiasing\n","  total_padding = padding * 2. + line_diameter\n","  new_scale = float(side) / float(original_side + total_padding)\n","  ctx.scale(new_scale, new_scale)\n","  ctx.translate(total_padding / 2., total_padding / 2.)\n","      \n","  bbox = np.hstack(vector_image).max(axis=1)\n","  offset = ((original_side, original_side) - bbox) / 2.\n","  offset = offset.reshape(-1,1)\n","  centered = [stroke + offset for stroke in vector_image]\n","\n","  # clear background\n","  ctx.set_source_rgb(*bg_color)\n","  ctx.paint()\n","\n","  # draw strokes, this is the most cpu-intensive part\n","  ctx.set_source_rgb(*fg_color)     \n","  for xv, yv in centered:   \n","    ctx.move_to(xv[0], yv[0])\n","    for x, y in zip(xv, yv):\n","        ctx.line_to(x, y)\n","    ctx.stroke()\n","\n","  data = surface.get_data()\n","  raster = np.copy(np.asarray(data)[::4]).reshape(side, side)\n","  return raster\n","\n","# Define transformation(s) to be applied to dataset-\n","transforms_norm = T.Compose(\n","      [\n","          T.ToTensor(), # scales integer inputs in the range [0, 255] into the range [0.0, 1.0]\n","          T.Normalize(mean=(0.138), std=(0.296)) # Quickdraw mean and stdev (35.213, 75.588), divided by 255\n","      ]\n","  )\n","\n","# transform functions - take sketch image, return torch tensor of descriptors\n","def transform(vector_img, is_test):\n","  raster = vector_to_raster(vector_img)\n","  raster = transforms_norm(raster)\n","\n","  # add rotations and translations at test time\n","  if is_test: \n","    angle = random.random()*60 - 30\n","    deltaX = random.randint(-10, 10)\n","    deltaY = random.randint(-10, 10)\n","\n","    raster = T.functional.affine(raster, angle, [deltaX, deltaY], 1, 0,\n","                                 interpolation=T.InterpolationMode.BILINEAR)\n","  return raster\n","\n","# helper method to find class based on imgset index\n","def find_class(idx, num_list):\n","  class_id = 0\n","  sum = num_list[class_id]\n","  while idx >= sum:\n","    class_id += 1\n","    sum += num_list[class_id]\n","  return class_id\n","\n","# deterministic worker re-seeding\n","def seed_worker(worker_id):\n","  worker_seed = torch.initial_seed() % 2**32\n","  np.random.seed(worker_seed)\n","  random.seed(worker_seed)\n","\n","# custom dataset for quickdraw\n","class QuickdrawDataset(Dataset):\n","  def __init__(self, imgs, nums, is_test):\n","    self.imgs = imgs\n","    self.nums = nums\n","    self.len = sum(nums)\n","    self.is_test = is_test\n","\n","  def __len__(self):\n","    return self.len\n","\n","  def __getitem__(self, idx):\n","    img = self.imgs[idx]\n","    x = transform(img, self.is_test)\n","    y = find_class(idx, self.nums)\n","    return x, y\n","\n","\n","# class CNN(nn.Module):\n","#     def __init__(self):\n","#         super(CNN, self).__init__()\n","#         self.conv1 = nn.Conv2d(1, 64, 3)\n","#         self.conv2 = nn.Conv2d(64, 64, 3)\n","#         self.conv3 = nn.Conv2d(64, 64, 3)\n","#         self.conv4 = nn.Conv2d(64, 64, 3)\n","#         self.maxpool = nn.MaxPool2d(2) \n","#         self.relu = nn.ReLU()\n","#         self.fc1 = nn.Linear(64 * 4 * 4, 384)\n","#         self.head = nn.Linear(384, NUM_CLASSES)\n","\n","#     def forward(self, x):\n","#         x = self.conv1(x)\n","#         x = self.relu(x)\n","#         x = self.conv2(x)\n","#         x = self.relu(x)\n","#         x = self.maxpool(x)\n","#         x = self.conv3(x)\n","#         x = self.relu(x)\n","#         x = self.conv4(x)\n","#         x = self.relu(x)\n","#         x = self.maxpool(x)\n","#         x = torch.flatten(x, 1)\n","#         x = self.fc1(x)\n","#         x = self.relu(x)\n","#         return self.head(x)\n","\n","\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, stride=2, padding=1)\n","        self.conv2 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n","        self.conv3 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n","        self.conv4 = nn.Conv2d(64, 64, 3, stride=2, padding=1)\n","        self.conv5 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n","        self.conv6 = nn.Conv2d(128, 128, 3, stride=2, padding=1)\n","        self.maxpool = nn.MaxPool2d(2) \n","        self.relu = nn.ReLU()\n","        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n","        self.head = nn.Linear(512, NUM_CLASSES)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        # x = self.maxpool(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        # x = self.maxpool(x)\n","        x = self.relu(x)\n","        x = self.conv3(x)\n","        # x = self.maxpool(x)\n","        x = self.relu(x)\n","        x = self.conv4(x)\n","        # x = self.maxpool(x)\n","        x = self.relu(x)\n","        x = self.conv5(x)\n","        # x = self.maxpool(x)\n","        x = self.relu(x)\n","        x = self.conv6(x)\n","        # x = self.maxpool(x)\n","        x = self.relu(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        return self.head(x)\n","\n","\n","def train_loop(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train() # put the model in train mode\n","    total_loss = 0\n","    total_correct = 0\n","    # for each batch in the training set compute loss and update model parameters\n","    for batch, (x, y) in enumerate(dataloader):\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      # Compute prediction and loss\n","      out = model(x)\n","      loss = loss_fn(out, y)\n","\n","      # Backpropagation to update model parameters\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","      # print current training metrics for user\n","      y, out, loss = y.to(\"cpu\"), out.to(\"cpu\"), loss.to(\"cpu\")\n","      loss_val = loss.item()\n","      if batch % 50 == 0:\n","          current = (batch + 1) * BATCH_SIZE\n","          print(f\"loss: {loss_val:>7f}  [{current:>5d}/{size:>5d}]\")\n","\n","      pred = out.argmax(dim=1, keepdim=True)\n","      correct = pred.eq(y.view_as(pred)).sum().item()\n","      total_correct += correct\n","      total_loss += loss_val\n","      # print(f\"train loss: {loss_val:>7f}   train accuracy: {correct / BATCH_SIZE:>7f}   [batch: {batch + 1:>3d}/{(size // BATCH_SIZE) + 1:>3d}]\")      \n","    print(f\"\\nepoch avg train loss: {total_loss / ((size // BATCH_SIZE) + 1):>7f}   epoch avg train accuracy: {total_correct / size:>7f}\")\n","      \n","def eval_loop(dataloader, model):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  with torch.no_grad():\n","    total_correct = 0\n","    for x, y in dataloader:\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      out = model(x)\n","      y, out = y.to(\"cpu\"), out.to(\"cpu\")\n","      pred = out.argmax(dim=1, keepdim=True)\n","      total_correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    accuracy = total_correct / size\n","    return accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yQmzmk8hsDL"},"outputs":[],"source":["# define methods for unpacking Quickdraw .bin files\n","def unpack_drawing(file_handle):\n","  file_handle.read(15)\n","  n_strokes, = unpack('H', file_handle.read(2))\n","  image = []\n","  for i in range(n_strokes):\n","      n_points, = unpack('H', file_handle.read(2))\n","      fmt = str(n_points) + 'B'\n","      x = unpack(fmt, file_handle.read(n_points))\n","      y = unpack(fmt, file_handle.read(n_points))\n","      image.append((x, y))\n","\n","  return image\n","\n","\n","def unpack_drawings(filename):\n","  imageset = []\n","  with open(filename, 'rb') as f:\n","      while True:\n","          try:\n","              imageset.append(unpack_drawing(f))\n","          except struct.error:\n","              break\n","  return imageset\n","\n","train_dir = '/content/drive/My Drive/Fourier/Quickdraw Dataset Small/Train/'\n","test_dir = '/content/drive/My Drive/Fourier/Quickdraw Dataset Small/Test/'\n","train_imgs = []\n","test_imgs = []\n","train_nums = []\n","test_nums = []\n","list_of_classes = [\"arm\", \"brain\", \"circle\", \"ear\", \"elbow\", \"eye\", \n","                   \"face\", \"finger\", \"foot\", \"hand\", \"hexagon\", \"knee\", \n","                   \"leg\", \"line\", \"mouth\", \"nose\", \"octagon\", \n","                   'skull', 'square', 'squiggle', 'star', 'toe', 'tooth', \n","                   'triangle', 'zigzag']\n","# list_of_classes = [\"aircraft carrier\", \"airplane\", \"alarm clock\", \"ambulance\", \n","#                    \"angel\", \"ant\", \"anvil\", \"apple\", \"arm\", \"asparagus\", \"axe\", \n","#                    \"backpack\", \"banana\", \"bandage\", \"barn\", \"baseball bat\", \n","#                    \"baseball\", \"basket\", \"basketball\", \"bathtub\", \"beach\", \"bear\", \n","#                    \"beard\", \"bed\", \"bee\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNCgN-LshS9t"},"outputs":[],"source":["# load dataset\n","for item in list_of_classes:\n","  train_folder = train_dir + item + '.bin'\n","  test_folder = test_dir + item + '.bin'\n","  train_drawings = unpack_drawings(train_folder)\n","  train_imgs += train_drawings\n","  train_nums.append(len(train_drawings))\n","  test_drawings = unpack_drawings(test_folder)\n","  test_imgs += test_drawings\n","  test_nums.append(len(test_drawings))"]},{"cell_type":"code","source":["DEVICE = \"cpu\"\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","\n","def get_confusion_mat(dataloader, model):\n","  model.eval()\n","  size = len(dataloader.dataset)\n","  conf_mat = np.zeros((NUM_CLASSES, NUM_CLASSES))\n","  with torch.no_grad():\n","    total_correct = 0\n","    for x, y in dataloader:\n","      x, y = x.to(DEVICE), y.to(DEVICE)\n","      out = model(x)\n","      y, out = y.to(\"cpu\"), out.to(\"cpu\")\n","      pred = out.argmax(dim=1, keepdim=True)\n","      y = y.view_as(pred)\n","      total_correct += pred.eq(y).sum().item()\n","      y, pred = y.numpy(), pred.numpy()\n","      indices = np.concatenate((y, pred), axis=1)\n","      for i in range(indices.shape[0]):\n","        conf_mat[indices[i, 0], indices[i, 1]] += 1\n","\n","    accuracy = total_correct / size\n","    print(f\"test accuracy: {accuracy:>7f}\")\n","    return conf_mat\n","\n","eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","model = CNN()\n","checkpoint = torch.load(LOAD_PATH, map_location=torch.device(DEVICE))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","\n","random.seed(RAND_SEED)\n","conf_mat = get_confusion_mat(dataloader=eval_loader,model=model)\n","conf_mat_norm = conf_mat * (255 / 100)\n","cv2_imshow(conf_mat_norm)\n","\n","diag = np.diagonal(conf_mat)\n","sums = np.asarray(test_nums)\n","accuracies = diag / sums\n","acc_sorted_idxs = np.argsort(accuracies)\n","for i in range(NUM_CLASSES):\n","  print(list_of_classes[acc_sorted_idxs[i]] + \" accuracy \" + str(accuracies[acc_sorted_idxs[i]]))\n","\n","print(\"\\n\")\n","\n","diag_mat = np.multiply(np.identity(NUM_CLASSES), conf_mat)\n","conf_mat_nodiag = conf_mat - diag_mat\n","conf_mat_sorted = np.argsort(conf_mat_nodiag, axis=None)\n","for i in range(1, 6):\n","  print(\"class \" + list_of_classes[conf_mat_sorted[-i] // NUM_CLASSES] + \" misclassified as \" + list_of_classes[conf_mat_sorted[-i] % NUM_CLASSES])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":615},"id":"QPjgOeaIjq0c","executionInfo":{"status":"ok","timestamp":1663270119038,"user_tz":420,"elapsed":69505,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"0fff35e7-e64e-4055-d88b-f7b0646133cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test accuracy: 0.767107\n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=L size=25x25 at 0x7F1A7DE47E10>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAABkAAAAZCAAAAADhgtq/AAABBklEQVR4nE2RrUpEURSFPz5YbDhcGAbkxonzWD6D72KyWCxisYvRItgEi8UiyBRfwXDOuWPbbNZef5sHYCWmQQnAYgPhBWABI6yyAcgJEWAsyJjSXnEBUNA4gA15BnewBwNoGBJ8CKIsg9BJ7XdHU5Cp2Fl9tEFQQI4Qani+XfDC1kl2cbPa/N6MS3dADdV3BVcnIN25wv2BQd7+HXqA9e7C2QM5dyLxNJcgqCMM8jOXPZAS9lgr3CGSKoDWA3oZhCutHrizrpsYn+eQfeglCfzOMstghVDNaLhR3ePZ9ZzbFxJSpnS3bySm27+2v0tI6ynK/os3tpDDBW175SymemYKOAI8/QEJ+BhqBMhztAAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["octagon accuracy 0.44\n","toe accuracy 0.5858585858585859\n","squiggle accuracy 0.6\n","foot accuracy 0.62\n","leg accuracy 0.64\n","nose accuracy 0.64\n","knee accuracy 0.66\n","arm accuracy 0.67\n","finger accuracy 0.69\n","zigzag accuracy 0.73\n","elbow accuracy 0.74\n","brain accuracy 0.77\n","ear accuracy 0.79\n","tooth accuracy 0.8\n","hexagon accuracy 0.83\n","eye accuracy 0.84\n","skull accuracy 0.86\n","star accuracy 0.88\n","hand accuracy 0.9\n","triangle accuracy 0.9\n","face accuracy 0.9\n","mouth accuracy 0.91\n","line accuracy 0.92\n","circle accuracy 0.92\n","square accuracy 0.94\n","\n","\n","class arm misclassified as square\n","class arm misclassified as circle\n","class arm misclassified as line\n","class arm misclassified as mouth\n","class arm misclassified as face\n"]}]},{"cell_type":"code","source":["diag_mat = np.multiply(np.identity(NUM_CLASSES), conf_mat)\n","conf_mat_nodiag = conf_mat - diag_mat\n","conf_mat_sorted = np.argsort(conf_mat_nodiag, axis=None)\n","for i in range(1, 6):\n","  print(\"class \" + list_of_classes[conf_mat_sorted[-i] // NUM_CLASSES] + \" misclassified as \" + list_of_classes[conf_mat_sorted[-i] % NUM_CLASSES])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JyF6s_PpqNl0","executionInfo":{"status":"ok","timestamp":1663271035617,"user_tz":420,"elapsed":196,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"d4a342f8-6bb7-4b9d-a911-4759a3983506"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["class octagon misclassified as hexagon\n","class zigzag misclassified as squiggle\n","class finger misclassified as toe\n","class knee misclassified as leg\n","class leg misclassified as foot\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 CNN baseline 256 no pool.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gus8KHxv4MhM","executionInfo":{"status":"ok","timestamp":1664482891494,"user_tz":420,"elapsed":509994,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"97d898c0-9137-4683-ee71-fc9230fc1f9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.215159  [  128/25000]\n","loss: 1.965218  [ 6528/25000]\n","loss: 1.599877  [12928/25000]\n","loss: 1.217440  [19328/25000]\n","\n","epoch avg train loss: 1.649858   epoch avg train accuracy: 0.510040\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.275178  [  128/25000]\n","loss: 1.112569  [ 6528/25000]\n","loss: 0.964037  [12928/25000]\n","loss: 1.005727  [19328/25000]\n","\n","epoch avg train loss: 1.028137   epoch avg train accuracy: 0.691840\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.882377  [  128/25000]\n","loss: 0.770213  [ 6528/25000]\n","loss: 0.759027  [12928/25000]\n","loss: 0.788708  [19328/25000]\n","\n","epoch avg train loss: 0.820373   epoch avg train accuracy: 0.751880\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.725505  [  128/25000]\n","loss: 0.627760  [ 6528/25000]\n","loss: 0.802505  [12928/25000]\n","loss: 0.809654  [19328/25000]\n","\n","epoch avg train loss: 0.663724   epoch avg train accuracy: 0.793160\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.518464  [  128/25000]\n","loss: 0.445447  [ 6528/25000]\n","loss: 0.426211  [12928/25000]\n","loss: 0.553010  [19328/25000]\n","\n","epoch avg train loss: 0.529809   epoch avg train accuracy: 0.830480\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.396684  [  128/25000]\n","loss: 0.380928  [ 6528/25000]\n","loss: 0.424196  [12928/25000]\n","loss: 0.475112  [19328/25000]\n","\n","epoch avg train loss: 0.410864   epoch avg train accuracy: 0.860040\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.285379  [  128/25000]\n","loss: 0.238925  [ 6528/25000]\n","loss: 0.358898  [12928/25000]\n","loss: 0.306537  [19328/25000]\n","\n","epoch avg train loss: 0.302072   epoch avg train accuracy: 0.898000\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.204987  [  128/25000]\n","loss: 0.237611  [ 6528/25000]\n","loss: 0.320578  [12928/25000]\n","loss: 0.263165  [19328/25000]\n","\n","epoch avg train loss: 0.236563   epoch avg train accuracy: 0.919240\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.188887  [  128/25000]\n","loss: 0.229849  [ 6528/25000]\n","loss: 0.224461  [12928/25000]\n","loss: 0.206617  [19328/25000]\n","\n","epoch avg train loss: 0.174880   epoch avg train accuracy: 0.941120\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.095372  [  128/25000]\n","loss: 0.168746  [ 6528/25000]\n","loss: 0.157158  [12928/25000]\n","loss: 0.139310  [19328/25000]\n","\n","epoch avg train loss: 0.146660   epoch avg train accuracy: 0.948400\n","\n","-------------------------------\n","\n","0.5460584233693477\n","0.006689259285783714\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 CNN baseline 28.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnWy34QfwQz1","executionInfo":{"status":"ok","timestamp":1664481100709,"user_tz":420,"elapsed":157076,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"dcfa0111-5ba6-4a97-d564-58575f103dbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.218138  [  512/25000]\n","loss: 2.311960  [ 5632/25000]\n","loss: 1.955709  [10752/25000]\n","loss: 1.801892  [15872/25000]\n","loss: 1.498721  [20992/25000]\n","\n","epoch avg train loss: 2.031463   epoch avg train accuracy: 0.408520\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.512664  [  512/25000]\n","loss: 1.488144  [ 5632/25000]\n","loss: 1.255664  [10752/25000]\n","loss: 1.250665  [15872/25000]\n","loss: 1.268072  [20992/25000]\n","\n","epoch avg train loss: 1.297988   epoch avg train accuracy: 0.617600\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 1.146265  [  512/25000]\n","loss: 1.072307  [ 5632/25000]\n","loss: 1.054770  [10752/25000]\n","loss: 1.045690  [15872/25000]\n","loss: 1.003103  [20992/25000]\n","\n","epoch avg train loss: 1.033741   epoch avg train accuracy: 0.693160\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.902011  [  512/25000]\n","loss: 0.860329  [ 5632/25000]\n","loss: 1.002645  [10752/25000]\n","loss: 0.954934  [15872/25000]\n","loss: 0.970173  [20992/25000]\n","\n","epoch avg train loss: 0.899375   epoch avg train accuracy: 0.732640\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.835649  [  512/25000]\n","loss: 0.707095  [ 5632/25000]\n","loss: 0.890652  [10752/25000]\n","loss: 0.893953  [15872/25000]\n","loss: 0.736130  [20992/25000]\n","\n","epoch avg train loss: 0.804719   epoch avg train accuracy: 0.757160\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.612897  [  512/25000]\n","loss: 0.669680  [ 5632/25000]\n","loss: 0.727648  [10752/25000]\n","loss: 0.638159  [15872/25000]\n","loss: 0.725492  [20992/25000]\n","\n","epoch avg train loss: 0.719727   epoch avg train accuracy: 0.783560\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.703327  [  512/25000]\n","loss: 0.638120  [ 5632/25000]\n","loss: 0.570880  [10752/25000]\n","loss: 0.527448  [15872/25000]\n","loss: 0.745350  [20992/25000]\n","\n","epoch avg train loss: 0.646088   epoch avg train accuracy: 0.802640\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.665177  [  512/25000]\n","loss: 0.642405  [ 5632/25000]\n","loss: 0.500174  [10752/25000]\n","loss: 0.610418  [15872/25000]\n","loss: 0.534942  [20992/25000]\n","\n","epoch avg train loss: 0.595570   epoch avg train accuracy: 0.814680\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.519745  [  512/25000]\n","loss: 0.625696  [ 5632/25000]\n","loss: 0.475307  [10752/25000]\n","loss: 0.521284  [15872/25000]\n","loss: 0.611305  [20992/25000]\n","\n","epoch avg train loss: 0.530004   epoch avg train accuracy: 0.833040\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.454694  [  512/25000]\n","loss: 0.504861  [ 5632/25000]\n","loss: 0.450258  [10752/25000]\n","loss: 0.399944  [15872/25000]\n","loss: 0.518780  [20992/25000]\n","\n","epoch avg train loss: 0.464957   epoch avg train accuracy: 0.850800\n","\n","-------------------------------\n","\n","0.12016806722689076\n","0.006738985374139825\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25-2 CNN baseline 256.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IMnd032BhBvm","executionInfo":{"status":"ok","timestamp":1664477345487,"user_tz":420,"elapsed":792213,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"f7450e10-d999-4b55-9e7f-21c5105e63a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.221095  [  128/24999]\n","loss: 2.173836  [ 6528/24999]\n","loss: 1.980121  [12928/24999]\n","loss: 1.215533  [19328/24999]\n","\n","epoch avg train loss: 1.816887   epoch avg train accuracy: 0.468459\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.287434  [  128/24999]\n","loss: 0.953429  [ 6528/24999]\n","loss: 1.114062  [12928/24999]\n","loss: 0.919442  [19328/24999]\n","\n","epoch avg train loss: 0.914766   epoch avg train accuracy: 0.738870\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.699980  [  128/24999]\n","loss: 0.740001  [ 6528/24999]\n","loss: 0.690159  [12928/24999]\n","loss: 0.638084  [19328/24999]\n","\n","epoch avg train loss: 0.698257   epoch avg train accuracy: 0.798592\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.531516  [  128/24999]\n","loss: 0.732716  [ 6528/24999]\n","loss: 0.555673  [12928/24999]\n","loss: 0.611803  [19328/24999]\n","\n","epoch avg train loss: 0.572231   epoch avg train accuracy: 0.831873\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.529996  [  128/24999]\n","loss: 0.353951  [ 6528/24999]\n","loss: 0.478967  [12928/24999]\n","loss: 0.392253  [19328/24999]\n","\n","epoch avg train loss: 0.460898   epoch avg train accuracy: 0.864195\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.253354  [  128/24999]\n","loss: 0.423175  [ 6528/24999]\n","loss: 0.382276  [12928/24999]\n","loss: 0.274055  [19328/24999]\n","\n","epoch avg train loss: 0.365634   epoch avg train accuracy: 0.887796\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.191770  [  128/24999]\n","loss: 0.205915  [ 6528/24999]\n","loss: 0.281120  [12928/24999]\n","loss: 0.369927  [19328/24999]\n","\n","epoch avg train loss: 0.284920   epoch avg train accuracy: 0.911556\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.166585  [  128/24999]\n","loss: 0.123122  [ 6528/24999]\n","loss: 0.199979  [12928/24999]\n","loss: 0.218708  [19328/24999]\n","\n","epoch avg train loss: 0.216483   epoch avg train accuracy: 0.929397\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.112948  [  128/24999]\n","loss: 0.158070  [ 6528/24999]\n","loss: 0.169690  [12928/24999]\n","loss: 0.144516  [19328/24999]\n","\n","epoch avg train loss: 0.174107   epoch avg train accuracy: 0.942838\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.106946  [  128/24999]\n","loss: 0.114284  [ 6528/24999]\n","loss: 0.192046  [12928/24999]\n","loss: 0.114224  [19328/24999]\n","\n","epoch avg train loss: 0.143202   epoch avg train accuracy: 0.953038\n","\n","-------------------------------\n","\n","0.6596533333333332\n","0.007677314345235283\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/Subset25 CNN baseline 256.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2dvk5UdLvg-","executionInfo":{"status":"ok","timestamp":1663264327765,"user_tz":420,"elapsed":749412,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"4719437f-e30d-45aa-b148-734459508ebc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","\n","loss: 3.215283  [  128/25000]\n","loss: 1.917566  [ 6528/25000]\n","loss: 1.432460  [12928/25000]\n","loss: 1.097957  [19328/25000]\n","\n","epoch avg train loss: 1.550189   epoch avg train accuracy: 0.535440\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.091581  [  128/25000]\n","loss: 1.002626  [ 6528/25000]\n","loss: 0.751829  [12928/25000]\n","loss: 0.809524  [19328/25000]\n","\n","epoch avg train loss: 0.888813   epoch avg train accuracy: 0.734640\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.794531  [  128/25000]\n","loss: 0.715321  [ 6528/25000]\n","loss: 0.647214  [12928/25000]\n","loss: 0.691696  [19328/25000]\n","\n","epoch avg train loss: 0.718833   epoch avg train accuracy: 0.779600\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.587544  [  128/25000]\n","loss: 0.600346  [ 6528/25000]\n","loss: 0.669575  [12928/25000]\n","loss: 0.814611  [19328/25000]\n","\n","epoch avg train loss: 0.601495   epoch avg train accuracy: 0.813400\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.573084  [  128/25000]\n","loss: 0.484653  [ 6528/25000]\n","loss: 0.559579  [12928/25000]\n","loss: 0.518491  [19328/25000]\n","\n","epoch avg train loss: 0.517855   epoch avg train accuracy: 0.834120\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.405074  [  128/25000]\n","loss: 0.376134  [ 6528/25000]\n","loss: 0.351805  [12928/25000]\n","loss: 0.580511  [19328/25000]\n","\n","epoch avg train loss: 0.431385   epoch avg train accuracy: 0.860920\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.353647  [  128/25000]\n","loss: 0.315415  [ 6528/25000]\n","loss: 0.468340  [12928/25000]\n","loss: 0.258686  [19328/25000]\n","\n","epoch avg train loss: 0.358760   epoch avg train accuracy: 0.881480\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.267187  [  128/25000]\n","loss: 0.220844  [ 6528/25000]\n","loss: 0.298653  [12928/25000]\n","loss: 0.327781  [19328/25000]\n","\n","epoch avg train loss: 0.285033   epoch avg train accuracy: 0.902760\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.171150  [  128/25000]\n","loss: 0.301800  [ 6528/25000]\n","loss: 0.104821  [12928/25000]\n","loss: 0.188208  [19328/25000]\n","\n","epoch avg train loss: 0.220418   epoch avg train accuracy: 0.924840\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.135594  [  128/25000]\n","loss: 0.153699  [ 6528/25000]\n","loss: 0.195032  [12928/25000]\n","loss: 0.290106  [19328/25000]\n","\n","epoch avg train loss: 0.186672   epoch avg train accuracy: 0.935680\n","\n","-------------------------------\n","\n","0.6561424569827932\n","0.006538791768921086\n"]}]},{"cell_type":"code","source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","checkpoint = torch.load(LOAD_PATH, map_location=torch.device(DEVICE))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","epoch = checkpoint['epoch']\n","# epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/CNN subset256.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTPkKbGeJAY_","executionInfo":{"status":"ok","timestamp":1663128825025,"user_tz":420,"elapsed":898217,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"97bdf195-e2dc-4842-f720-a9bd78c72ecb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 11\n","\n","loss: 0.085136  [  128/28000]\n","loss: 0.225925  [ 6528/28000]\n","loss: 0.222469  [12928/28000]\n","loss: 0.159301  [19328/28000]\n","loss: 0.082144  [25728/28000]\n","\n","epoch avg train loss: 0.166116   epoch avg train accuracy: 0.942071\n","\n","-------------------------------\n","\n","Epoch 12\n","\n","loss: 0.151190  [  128/28000]\n","loss: 0.050427  [ 6528/28000]\n","loss: 0.145639  [12928/28000]\n","loss: 0.176640  [19328/28000]\n","loss: 0.117802  [25728/28000]\n","\n","epoch avg train loss: 0.146608   epoch avg train accuracy: 0.947500\n","\n","-------------------------------\n","\n","Epoch 13\n","\n","loss: 0.126263  [  128/28000]\n","loss: 0.045405  [ 6528/28000]\n","loss: 0.076877  [12928/28000]\n","loss: 0.099668  [19328/28000]\n","loss: 0.097276  [25728/28000]\n","\n","epoch avg train loss: 0.130560   epoch avg train accuracy: 0.954786\n","\n","-------------------------------\n","\n","Epoch 14\n","\n","loss: 0.115557  [  128/28000]\n","loss: 0.092650  [ 6528/28000]\n","loss: 0.104343  [12928/28000]\n","loss: 0.079545  [19328/28000]\n","loss: 0.192434  [25728/28000]\n","\n","epoch avg train loss: 0.097053   epoch avg train accuracy: 0.966321\n","\n","-------------------------------\n","\n","Epoch 15\n","\n","loss: 0.027118  [  128/28000]\n","loss: 0.109605  [ 6528/28000]\n","loss: 0.128289  [12928/28000]\n","loss: 0.186329  [19328/28000]\n","loss: 0.099141  [25728/28000]\n","\n","epoch avg train loss: 0.096713   epoch avg train accuracy: 0.966500\n","\n","-------------------------------\n","\n","Epoch 16\n","\n","loss: 0.123029  [  128/28000]\n","loss: 0.118719  [ 6528/28000]\n","loss: 0.120225  [12928/28000]\n","loss: 0.039166  [19328/28000]\n","loss: 0.083992  [25728/28000]\n","\n","epoch avg train loss: 0.090891   epoch avg train accuracy: 0.969357\n","\n","-------------------------------\n","\n","Epoch 17\n","\n","loss: 0.158680  [  128/28000]\n","loss: 0.105676  [ 6528/28000]\n","loss: 0.087490  [12928/28000]\n","loss: 0.070200  [19328/28000]\n","loss: 0.089014  [25728/28000]\n","\n","epoch avg train loss: 0.082819   epoch avg train accuracy: 0.971893\n","\n","-------------------------------\n","\n","Epoch 18\n","\n","loss: 0.026985  [  128/28000]\n","loss: 0.130403  [ 6528/28000]\n","loss: 0.018654  [12928/28000]\n","loss: 0.077901  [19328/28000]\n","loss: 0.020883  [25728/28000]\n","\n","epoch avg train loss: 0.071677   epoch avg train accuracy: 0.975964\n","\n","-------------------------------\n","\n","Epoch 19\n","\n","loss: 0.050802  [  128/28000]\n","loss: 0.055104  [ 6528/28000]\n","loss: 0.044325  [12928/28000]\n","loss: 0.021931  [19328/28000]\n","loss: 0.090370  [25728/28000]\n","\n","epoch avg train loss: 0.061167   epoch avg train accuracy: 0.979464\n","\n","-------------------------------\n","\n","Epoch 20\n","\n","loss: 0.127993  [  128/28000]\n","loss: 0.115960  [ 6528/28000]\n","loss: 0.031121  [12928/28000]\n","loss: 0.089520  [19328/28000]\n","loss: 0.042992  [25728/28000]\n","\n","epoch avg train loss: 0.067124   epoch avg train accuracy: 0.977214\n","\n","-------------------------------\n","\n","0.633666785756818\n","0.0064549608460161305\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":644891,"status":"error","timestamp":1663119518794,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"},"user_tz":420},"id":"J1t1TKOBHG-R","outputId":"eb7a07e8-9460-4591-8717-e2b5cc30e702"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","\n","loss: 3.333196  [  128/28000]\n","loss: 1.414870  [12928/28000]\n","loss: 0.924474  [25728/28000]\n","\n","epoch avg train loss: 1.608316   epoch avg train accuracy: 0.530107\n","\n","-------------------------------\n","\n","Epoch 2\n","\n","loss: 1.053097  [  128/28000]\n","loss: 1.012632  [12928/28000]\n","loss: 1.032461  [25728/28000]\n","\n","epoch avg train loss: 0.937371   epoch avg train accuracy: 0.723857\n","\n","-------------------------------\n","\n","Epoch 3\n","\n","loss: 0.630781  [  128/28000]\n","loss: 0.908870  [12928/28000]\n","loss: 0.695954  [25728/28000]\n","\n","epoch avg train loss: 0.761911   epoch avg train accuracy: 0.769179\n","\n","-------------------------------\n","\n","Epoch 4\n","\n","loss: 0.649218  [  128/28000]\n","loss: 0.463790  [12928/28000]\n","loss: 0.612333  [25728/28000]\n","\n","epoch avg train loss: 0.643948   epoch avg train accuracy: 0.800107\n","\n","-------------------------------\n","\n","Epoch 5\n","\n","loss: 0.562698  [  128/28000]\n","loss: 0.766773  [12928/28000]\n","loss: 0.628773  [25728/28000]\n","\n","epoch avg train loss: 0.558278   epoch avg train accuracy: 0.822857\n","\n","-------------------------------\n","\n","Epoch 6\n","\n","loss: 0.478817  [  128/28000]\n","loss: 0.475577  [12928/28000]\n","loss: 0.521448  [25728/28000]\n","\n","epoch avg train loss: 0.465484   epoch avg train accuracy: 0.849893\n","\n","-------------------------------\n","\n","Epoch 7\n","\n","loss: 0.486195  [  128/28000]\n","loss: 0.395883  [12928/28000]\n","loss: 0.345044  [25728/28000]\n","\n","epoch avg train loss: 0.387679   epoch avg train accuracy: 0.873893\n","\n","-------------------------------\n","\n","Epoch 8\n","\n","loss: 0.239532  [  128/28000]\n","loss: 0.247684  [12928/28000]\n","loss: 0.201386  [25728/28000]\n","\n","epoch avg train loss: 0.305838   epoch avg train accuracy: 0.896750\n","\n","-------------------------------\n","\n","Epoch 9\n","\n","loss: 0.121853  [  128/28000]\n","loss: 0.261855  [12928/28000]\n","loss: 0.208235  [25728/28000]\n","\n","epoch avg train loss: 0.256351   epoch avg train accuracy: 0.913286\n","\n","-------------------------------\n","\n","Epoch 10\n","\n","loss: 0.207954  [  128/28000]\n","loss: 0.203252  [12928/28000]\n","loss: 0.207512  [25728/28000]\n","\n","epoch avg train loss: 0.201488   epoch avg train accuracy: 0.931036\n","\n","-------------------------------\n","\n","test accuracy: 0.639871\n","test accuracy: 0.634155\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-fd5e51af7da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRAND_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m   \u001b[0meval_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-7a8f319c4c0e>\u001b[0m in \u001b[0;36meval_loop\u001b[0;34m(dataloader, model)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mtotal_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-7a8f319c4c0e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-7a8f319c4c0e>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(vector_img, is_test)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raster = T.functional.affine(raster, angle, [deltaX, deltaY], 1, 0,\n\u001b[0;32m---> 65\u001b[0;31m                                  interpolation=T.InterpolationMode.BILINEAR)\n\u001b[0m\u001b[1;32m     66\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mraster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36maffine\u001b[0;34m(img, angle, translate, scale, shear, interpolation, fill, resample, fillcolor, center)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0mtranslate_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_inverse_affine_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslate_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36maffine\u001b[0;34m(img, matrix, interpolation, fill)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;31m# grid will be generated on the same device as theta and img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gen_affine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_apply_grid_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36m_apply_grid_transform\u001b[0;34m(img, grid, mode, fill)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;31m# Fill with required color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgrid_sample\u001b[0;34m(input, grid, mode, padding_mode, align_corners)\u001b[0m\n\u001b[1;32m   4221\u001b[0m         \u001b[0malign_corners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_enum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mode_enum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# seed RNGs\n","torch.manual_seed(RAND_SEED)\n","random.seed(RAND_SEED)\n","\n","# create datasets\n","train_data = QuickdrawDataset(train_imgs, train_nums, is_test=False)\n","# eval_data = QuickdrawDataset(test_imgs, test_nums, is_test=False)\n","test_data = QuickdrawDataset(test_imgs, test_nums, is_test=True)\n","\n","# create dataloaders\n","g = torch.Generator()\n","g.manual_seed(RAND_SEED)\n","train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, worker_init_fn=seed_worker, generator=g)\n","# eval_loader = DataLoader(eval_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, worker_init_fn=seed_worker, generator=g)\n","\n","# init model and optimizer\n","model = CNN()\n","# checkpoint = torch.load(SAVE_PATH, map_location=torch.device(DEVICE))\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(DEVICE)\n","optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","# optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","epoch = 0\n","\n","# train for EPOCHS number of epochs then evaluate on test data with affine transformations\n","SAVE_PATH = '/content/drive/My Drive/Fourier/Saved Models/CNN subset256.pt'\n","for i in range(epoch, EPOCHS):\n","    print(\"Epoch \" + str(i + 1) + \"\\n\")\n","    train_loop(dataloader=train_loader,model=model,loss_fn=LOSS_FN,optimizer=optim)\n","    # eval_loop(dataloader=eval_loader,model=model)\n","    torch.save({\n","                'epoch': i + 1,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optim.state_dict()\n","                }, SAVE_PATH)\n","    print(\"\\n-------------------------------\\n\")\n","random.seed(RAND_SEED)\n","for i in range(30):\n","  eval_loop(dataloader=test_loader,model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUEhx_zppiCW","executionInfo":{"status":"ok","timestamp":1663120386806,"user_tz":420,"elapsed":237170,"user":{"displayName":"Matthew Watson","userId":"04238265723475746974"}},"outputId":"a7c42421-e830-406f-cad2-6f525ab412c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.6389067524115755\n","0.007904832500237147\n"]}],"source":["random.seed(RAND_SEED)\n","accuracies = []\n","for i in range(30):\n","  accuracies.append(eval_loop(dataloader=test_loader,model=model))\n","accuracies = np.asarray(accuracies)\n","mean = np.mean(accuracies)\n","std = np.std(accuracies)\n","print(mean)\n","print(std)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1YbnaTcA2O78WEFXdGIOmPkDRM18AVJ2X","timestamp":1663109377147},{"file_id":"1-Zu9875EPh8lpZKZBL92PY0SI_EZj2R8","timestamp":1660851002402},{"file_id":"1HmEE3jGUpn2AzNnSdBfhtm74OSHAmt0o","timestamp":1650055586271},{"file_id":"1owTDTec1_uglqFzHWQQKQbfPBG9Ge_Ep","timestamp":1649121474527}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}